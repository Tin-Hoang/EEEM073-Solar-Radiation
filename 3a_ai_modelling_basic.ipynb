{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create PyTorch Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload to mode 2\n",
    "%autoreload 2\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "\n",
    "# Local modules\n",
    "from utils.data_persistence import load_scalers\n",
    "from utils.plot_utils import plot_training_history, plot_evaluation_metrics\n",
    "from utils.training_utils import train_model, evaluate_model\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# ========== Model training hyperparameters =========\n",
    "PATIENCE = 10\n",
    "LR = 0.001\n",
    "DEBUG_MODE = True\n",
    "\n",
    "if DEBUG_MODE:\n",
    "    # Local development settings (to check if the code is working)\n",
    "    N_EPOCHS = 10\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = 4\n",
    "else:\n",
    "    # Remote server settings (to train the model, recommend using Otter lab machine)\n",
    "    N_EPOCHS = 100\n",
    "    BATCH_SIZE = 2 ** 14   # = 16384\n",
    "    NUM_WORKERS = 16\n",
    "\n",
    "# ================= Wandb settings =============\n",
    "USE_WANDB = True\n",
    "WANDB_USERNAME = \"tin-hoang\"\n",
    "WANDB_PROJECT = \"EEEM073-Solar-Radiation\"\n",
    "\n",
    "# =========== Time series hyperparameters ===========\n",
    "# Number of timesteps to look back when creating sequences\n",
    "LOOKBACK = 24\n",
    "\n",
    "# Choose features to use in modeling\n",
    "TIME_KEY = 'time_features'\n",
    "SELECTED_FEATURES = [\n",
    "    'air_temperature',\n",
    "    'wind_speed',\n",
    "    'relative_humidity',\n",
    "    'cloud_type',\n",
    "    'solar_zenith_angle',\n",
    "    'clearsky_ghi',\n",
    "    'total_precipitable_water',\n",
    "    'surface_albedo',\n",
    "    'nighttime_mask',  # New field from preprocess_data\n",
    "]\n",
    "\n",
    "# Target variable\n",
    "TARGET_VARIABLE = 'ghi'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_persistence import load_normalized_data\n",
    "\n",
    "train_preprocessed_data_path = \"data/processed/train_normalized.h5\"\n",
    "val_preprocessed_data_path = \"data/processed/val_normalized.h5\"\n",
    "test_preprocessed_data_path = \"data/processed/test_normalized.h5\"\n",
    "\n",
    "# Load sequences\n",
    "train_data, metadata = load_normalized_data(train_preprocessed_data_path)\n",
    "\n",
    "scaler_path = \"data/processed/model_scalers.pkl\"\n",
    "scalers = load_scalers(scaler_path)\n",
    "\n",
    "# Print metadata\n",
    "print(f\"Train set | Metadata: {metadata}\")\n",
    "# Print created time\n",
    "print(f\"Train set | Created time: {metadata['created_time'] if 'created_time' in metadata else 'No created time'}\")\n",
    "# Print raw files\n",
    "print(f\"Train set | Raw files: {metadata['raw_files'] if 'raw_files' in metadata else 'No raw files'}\")\n",
    "\n",
    "# Print data structure and shape\n",
    "print(f\"Train set | Data structure:\")\n",
    "for key, value in train_data.items():\n",
    "    print(f\"  {key} shape: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.timeseriesdataset import TimeSeriesDataset\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TimeSeriesDataset(train_preprocessed_data_path, lookback=LOOKBACK, target_field=TARGET_VARIABLE, selected_features=SELECTED_FEATURES, include_target_history=False)\n",
    "val_dataset = TimeSeriesDataset(val_preprocessed_data_path, lookback=LOOKBACK, target_field=TARGET_VARIABLE, selected_features=SELECTED_FEATURES, include_target_history=False)\n",
    "test_dataset = TimeSeriesDataset(test_preprocessed_data_path, lookback=LOOKBACK, target_field=TARGET_VARIABLE, selected_features=SELECTED_FEATURES, include_target_history=False)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# Check sample batch\n",
    "print(\"=\"*100)\n",
    "sample_batch = next(iter(train_loader))\n",
    "for key, value in sample_batch.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key} shape: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch to determine input dimensions\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Extract dimensions from a batch (more reliable)\n",
    "temporal_features = batch['temporal_features']\n",
    "static_features = batch['static_features']\n",
    "\n",
    "# Check if we have 3D temporal features (batch, seq_len, features)\n",
    "if len(temporal_features.shape) == 3:\n",
    "    temporal_dim = temporal_features.shape[2]\n",
    "else:\n",
    "    # Handle 2D temporal features (batch, features)\n",
    "    temporal_dim = temporal_features.shape[1]\n",
    "\n",
    "static_dim = static_features.shape[1]\n",
    "\n",
    "print(f\"  Input dimensions determined from batch:\")\n",
    "print(f\"  - Batch temporal_features shape: {batch['temporal_features'].shape}\")\n",
    "print(f\"  - Batch static_features shape: {batch['static_features'].shape}\")\n",
    "print(f\"  - Temporal dimension: {temporal_dim}\")\n",
    "print(f\"  - Static dimension: {static_dim}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "from utils.training_utils import train_model, evaluate_model\n",
    "from utils.wandb_utils import is_wandb_enabled, set_wandb_flag, set_keep_run_open\n",
    "from utils.model_utils import print_model_info\n",
    "\n",
    "# Enable wandb tracking\n",
    "set_wandb_flag(USE_WANDB)\n",
    "# Keep the wandb run open after training to continue logging evaluation plots\n",
    "set_keep_run_open(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Setup Experiment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_pipeline(model, train_loader, val_loader, test_loader, model_name, epochs=30, patience=5, lr=0.001):\n",
    "    \"\"\"\n",
    "    Run the experiment pipeline for a given model.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        train_loader: The training data loader.\n",
    "        val_loader: The validation data loader.\n",
    "        test_loader: The test data loader.\n",
    "        model_name: The name of the model.\n",
    "        epochs: The number of epochs to train the model.\n",
    "        patience: The number of epochs to wait before early stopping.\n",
    "        lr: The learning rate for the model.\n",
    "    \"\"\"\n",
    "    history, val_metrics, test_metrics = None, None, None\n",
    "\n",
    "    try:\n",
    "        print(f\"Training {model_name} model...\")\n",
    "        history = train_model(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            model_name=model_name,\n",
    "            epochs=epochs,\n",
    "            patience=patience,\n",
    "            lr=lr,\n",
    "            debug_mode=DEBUG_MODE,\n",
    "            target_scaler=scalers[f'{TARGET_VARIABLE}_scaler']\n",
    "        )\n",
    "        training_plot = plot_training_history(history, model_name=model_name)\n",
    "\n",
    "        print(f\"\\nEvaluating {model_name} model on test set...\")\n",
    "        test_metrics = evaluate_model(\n",
    "            model,\n",
    "            test_loader,\n",
    "            scalers[f'{TARGET_VARIABLE}_scaler'],\n",
    "            model_name=f\"{model_name} - Test\"\n",
    "        )\n",
    "        test_plot = plot_evaluation_metrics(test_metrics, model_name=f\"{model_name} - Test\")\n",
    "\n",
    "        # Log the test plot to wandb\n",
    "        if is_wandb_enabled():\n",
    "            wandb.log({\"plots/history_plot\": wandb.Image(training_plot)})\n",
    "            wandb.log({\"plots/predictions_plot\": wandb.Image(test_plot)})\n",
    "\n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), f'{model_name}_best.pt')\n",
    "\n",
    "    finally:\n",
    "        # Finish wandb run if it's still open\n",
    "        if is_wandb_enabled():\n",
    "            wandb.finish()\n",
    "\n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return history, val_metrics, test_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm import LSTMModel\n",
    "\n",
    "# Create LSTM model\n",
    "lstm_model = LSTMModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(lstm_model, temporal_features.shape, static_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LSTM\"\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_history, lstm_val_metrics, lstm_test_metrics = run_experiment_pipeline(\n",
    "    lstm_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Multi-Layer Perceptron (MLP) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mlp import MLPModel\n",
    "\n",
    "# Create MLP model\n",
    "mlp_model = MLPModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    hidden_dims=[256, 512, 256, 128],\n",
    "    dropout=0.3,\n",
    "    lookback=LOOKBACK\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(mlp_model, temporal_features.shape, static_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MLP\"\n",
    "\n",
    "# Train the MLP model\n",
    "mlp_history, mlp_val_metrics, mlp_test_metrics = run_experiment_pipeline(\n",
    "    mlp_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 CNN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn_lstm import CNNLSTMModel\n",
    "\n",
    "# Create CNN-LSTM model\n",
    "cnn_lstm_model = CNNLSTMModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    hidden_dim=128,\n",
    "    num_filters=64,\n",
    "    kernel_size=3,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(cnn_lstm_model, temporal_features.shape, static_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CNN-LSTM\"\n",
    "\n",
    "# Train the LSTM model\n",
    "cnn_lstm_history, cnn_lstm_val_metrics, cnn_lstm_test_metrics = run_experiment_pipeline(\n",
    "    cnn_lstm_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Multi-Layer Perceptron (MLP) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mlp import MLPModel\n",
    "\n",
    "# Create MLP model\n",
    "mlp_model = MLPModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    hidden_dims=[256, 512, 256, 128],\n",
    "    dropout=0.3,\n",
    "    lookback=LOOKBACK\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(mlp_model, temporal_features.shape, static_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MLP\"\n",
    "\n",
    "# Train the MLP model\n",
    "mlp_history, mlp_val_metrics, mlp_test_metrics = run_experiment_pipeline(\n",
    "    mlp_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 1D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn1d import CNN1DModel\n",
    "\n",
    "# Create MLP model\n",
    "cnn1d_model = CNN1DModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    num_filters=[64, 128, 256],\n",
    "    kernel_sizes=[3, 3, 3],\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "# Print the model\n",
    "print_model_info(cnn1d_model, temporal_features.shape, static_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(\n",
    "    cnn1d_model,\n",
    "    input_data=[\n",
    "        torch.zeros(temporal_features.shape),\n",
    "        torch.zeros(static_features.shape)\n",
    "    ],\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"1D-CNN\"\n",
    "\n",
    "# Train the MLP model\n",
    "cnn1d_history, cnn1d_val_metrics, cnn1d_test_metrics = run_experiment_pipeline(\n",
    "    cnn1d_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Compare Models' Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import compare_models\n",
    "\n",
    "# Create a dictionary of model metrics\n",
    "model_metrics = {\n",
    "    'LSTM': lstm_test_metrics,\n",
    "    'CNN-LSTM': cnn_lstm_test_metrics,\n",
    "    'MLP': mlp_test_metrics,\n",
    "    '1D-CNN': cnn1d_test_metrics\n",
    "}\n",
    "\n",
    "# Compare model performance on test set\n",
    "print(\"\\nTest Set Comparison:\")\n",
    "compare_models(model_metrics, dataset_name='Test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Model Comparison on Daytime/Nighttime/Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import compare_models_daytime_nighttime\n",
    "\n",
    "# Create a dictionary of model metrics\n",
    "model_metrics = {\n",
    "    'LSTM': lstm_test_metrics,\n",
    "    'CNN-LSTM': cnn_lstm_test_metrics,\n",
    "    'MLP': mlp_test_metrics,\n",
    "    '1D-CNN': cnn1d_test_metrics\n",
    "}\n",
    "\n",
    "# Generate the comparison plot\n",
    "comparison_fig = compare_models_daytime_nighttime(model_metrics, dataset_name='Test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Time Series Predictions\n",
    "\n",
    "Visualize predictions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_over_time(models, model_names, data_loader, target_scaler, num_samples=200, start_idx=0):\n",
    "    \"\"\"\n",
    "    Plot time series predictions for multiple models with nighttime shading if available\n",
    "\n",
    "    Args:\n",
    "        models: List of PyTorch models\n",
    "        model_names: List of model names\n",
    "        data_loader: Data loader\n",
    "        target_scaler: Scaler for the target variable\n",
    "        num_samples: Number of consecutive time steps to plot\n",
    "        start_idx: Starting index in the dataset\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    # Get device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Collect data samples\n",
    "    all_batches = []\n",
    "    for batch in data_loader:\n",
    "        all_batches.append(batch)\n",
    "        if len(all_batches) * batch['target'].shape[0] > start_idx + num_samples:\n",
    "            break\n",
    "\n",
    "    # Combine batches into a single dataset\n",
    "    all_temporal = []\n",
    "    all_static = []\n",
    "    all_targets = []\n",
    "    all_nighttime = []\n",
    "    has_nighttime = False\n",
    "\n",
    "    for batch in all_batches:\n",
    "        all_temporal.append(batch['temporal_features'])\n",
    "        all_static.append(batch['static_features'])\n",
    "        all_targets.append(batch['target'])\n",
    "        # Check if nighttime data is available\n",
    "        if 'nighttime' in batch:\n",
    "            has_nighttime = True\n",
    "            all_nighttime.append(batch['nighttime'])\n",
    "\n",
    "    all_temporal = torch.cat(all_temporal, dim=0)\n",
    "    all_static = torch.cat(all_static, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    if has_nighttime:\n",
    "        all_nighttime = torch.cat(all_nighttime, dim=0)\n",
    "\n",
    "    # Get the subset for visualization\n",
    "    temporal = all_temporal[start_idx:start_idx+num_samples].to(device)\n",
    "    static = all_static[start_idx:start_idx+num_samples].to(device)\n",
    "    targets = all_targets[start_idx:start_idx+num_samples].cpu().numpy()\n",
    "\n",
    "    if has_nighttime:\n",
    "        nighttime = all_nighttime[start_idx:start_idx+num_samples].cpu().numpy()\n",
    "        # Ensure nighttime is a 1D array\n",
    "        if len(nighttime.shape) > 1:\n",
    "            nighttime = nighttime.flatten() if nighttime.shape[1] == 1 else nighttime[:,0]\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(temporal, static).cpu().numpy()\n",
    "            predictions.append(outputs)\n",
    "\n",
    "    # Inverse transform to original scale\n",
    "    y_true_orig = target_scaler.inverse_transform(targets.reshape(-1, 1)).flatten()\n",
    "    y_pred_orig_list = [target_scaler.inverse_transform(pred.reshape(-1, 1)).flatten() for pred in predictions]\n",
    "\n",
    "    # Create visualization\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # If we have nighttime data, shade those regions\n",
    "    if has_nighttime:\n",
    "        # Create mask for continuous nighttime periods\n",
    "        nighttime_bool = (nighttime > 0.5)\n",
    "\n",
    "        # Shade nighttime regions\n",
    "        night_regions = []\n",
    "        start = None\n",
    "        for i, is_night in enumerate(nighttime_bool):\n",
    "            if is_night and start is None:\n",
    "                start = i\n",
    "            elif not is_night and start is not None:\n",
    "                night_regions.append((start, i))\n",
    "                start = None\n",
    "\n",
    "        # Handle case where the last region is nighttime\n",
    "        if start is not None:\n",
    "            night_regions.append((start, len(nighttime_bool)))\n",
    "\n",
    "        # Plot nighttime regions\n",
    "        for start, end in night_regions:\n",
    "            ax.axvspan(start, end, alpha=0.2, color='gray', label='_nolegend_')\n",
    "\n",
    "        # Only add nighttime to the legend once\n",
    "        if night_regions:\n",
    "            # Add dummy entry for nighttime legend\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            handles.append(Patch(facecolor='gray', alpha=0.2))\n",
    "            labels.append('Nighttime')\n",
    "            ax.legend(handles, labels)\n",
    "\n",
    "    # Plot predictions\n",
    "    plt.plot(y_true_orig, 'k-', label='Actual GHI', linewidth=2)\n",
    "\n",
    "    colors = ['b-', 'r-', 'g-', 'm-', 'c-', 'y-']\n",
    "    for i, (pred, name) in enumerate(zip(y_pred_orig_list, model_names)):\n",
    "        plt.plot(pred, colors[i % len(colors)], label=f'{name} Predicted', alpha=0.7)\n",
    "\n",
    "    # Calculate and display error metrics for the visualization window\n",
    "    for i, (pred, name) in enumerate(zip(y_pred_orig_list, model_names)):\n",
    "        rmse = np.sqrt(np.mean((y_true_orig - pred) ** 2))\n",
    "        mae = np.mean(np.abs(y_true_orig - pred))\n",
    "\n",
    "        # Add metrics annotation\n",
    "        plt.annotate(f\"{name}: RMSE={rmse:.2f}, MAE={mae:.2f}\",\n",
    "                     xy=(0.02, 0.97 - 0.03*i),\n",
    "                     xycoords='axes fraction',\n",
    "                     fontsize=9,\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "\n",
    "    plt.title('GHI Predictions Over Time')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('GHI (W/m²)')\n",
    "\n",
    "    # If we haven't added a legend yet (no nighttime data), add it now\n",
    "    if not has_nighttime or not night_regions:\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    plt.savefig(f'plots/predictions_over_time_{model_name}.png')\n",
    "    return fig\n",
    "\n",
    "# Plot time series predictions\n",
    "plot_predictions_over_time(\n",
    "    models=[lstm_model, cnn_lstm_model, mlp_model, cnn1d_model],\n",
    "    model_names=['LSTM', 'CNN-LSTM', 'MLP', '1D-CNN'],\n",
    "    data_loader=test_loader,\n",
    "    target_scaler=scalers[f'{TARGET_VARIABLE}_scaler'],\n",
    "    num_samples=72,\n",
    "    start_idx=0\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
