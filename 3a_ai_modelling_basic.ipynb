{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create PyTorch Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Load autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload to mode 2\n",
    "%autoreload 2\n",
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "\n",
    "from utils.data_persistence import load_scalers\n",
    "from utils.plot_utils import plot_training_history, plot_evaluation_metrics\n",
    "from utils.wandb_utils import setup_wandb\n",
    "from utils.training_utils import train_model, evaluate_model\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "# List of features to use\n",
    "AVAILABLE_FEATURES = [\n",
    "    'ghi',                     # Target variable\n",
    "    'air_temperature',         # Weather features\n",
    "    'wind_speed',\n",
    "    'relative_humidity',\n",
    "    'dew_point',\n",
    "    'surface_pressure',\n",
    "    'total_precipitable_water',\n",
    "    'cloud_type',              # Cloud features\n",
    "    'cloud_fill_flag',\n",
    "    'cld_opd_dcomp',\n",
    "    'cld_press_acha',\n",
    "    'cld_reff_dcomp',\n",
    "    'clearsky_ghi',            # Clear sky estimates\n",
    "    'clearsky_dni',\n",
    "    'clearsky_dhi',\n",
    "    'solar_zenith_angle',      # Solar geometry\n",
    "    'surface_albedo',          # Surface properties\n",
    "    'ozone',                   # Atmospheric properties\n",
    "    'aod',\n",
    "    'ssa',\n",
    "    'asymmetry',\n",
    "    'alpha'\n",
    "]\n",
    "\n",
    "# Choose features to use in modeling\n",
    "SELECTED_FEATURES = [\n",
    "    'air_temperature',\n",
    "    'wind_speed',\n",
    "    'relative_humidity',\n",
    "    'cloud_type',\n",
    "    'solar_zenith_angle',\n",
    "    'clearsky_ghi',\n",
    "    'total_precipitable_water',\n",
    "    'surface_albedo'\n",
    "]\n",
    "\n",
    "# Target variable\n",
    "TARGET_VARIABLE = 'ghi'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded normalized data from data/processed/train_normalized.h5\n",
      "Loaded 12 scalers from data/processed/model_scalers.pkl\n",
      "Train set | Metadata: {'created_time': '2025-04-25 05:36:18'}\n",
      "Train set | Created time: 2025-04-25 05:36:18\n",
      "Train set | Raw files: No raw files\n",
      "Train set | Data structure:\n",
      "  air_temperature shape: (8760, 105)\n",
      "  clearsky_ghi shape: (8760, 105)\n",
      "  cloud_type shape: (8760, 105)\n",
      "  coordinates shape: (105, 2)\n",
      "  elevation shape: (105,)\n",
      "  ghi shape: (8760, 105)\n",
      "  nighttime_mask shape: (8760, 105)\n",
      "  relative_humidity shape: (8760, 105)\n",
      "  solar_zenith_angle shape: (8760, 105)\n",
      "  surface_albedo shape: (8760, 105)\n",
      "  time_features shape: (8760, 8)\n",
      "  total_precipitable_water shape: (8760, 105)\n",
      "  wind_speed shape: (8760, 105)\n"
     ]
    }
   ],
   "source": [
    "from utils.data_persistence import load_normalized_data\n",
    "\n",
    "train_preprocessed_data_path = \"data/processed/train_normalized.h5\"\n",
    "val_preprocessed_data_path = \"data/processed/val_normalized.h5\"\n",
    "test_preprocessed_data_path = \"data/processed/test_normalized.h5\"\n",
    "\n",
    "# Load sequences\n",
    "train_data, metadata = load_normalized_data(train_preprocessed_data_path)\n",
    "\n",
    "scaler_path = \"data/processed/model_scalers.pkl\"\n",
    "scalers = load_scalers(scaler_path)\n",
    "\n",
    "# Print metadata\n",
    "print(f\"Train set | Metadata: {metadata}\")\n",
    "# Print created time\n",
    "print(f\"Train set | Created time: {metadata['created_time'] if 'created_time' in metadata else 'No created time'}\")\n",
    "# Print raw files\n",
    "print(f\"Train set | Raw files: {metadata['raw_files'] if 'raw_files' in metadata else 'No raw files'}\")\n",
    "\n",
    "# Print data structure and shape\n",
    "print(f\"Train set | Data structure:\")\n",
    "for key, value in train_data.items():\n",
    "    print(f\"  {key} shape: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded normalized data from data/processed/train_normalized.h5\n",
      "Loaded normalized data file (1/1): data/processed/train_normalized.h5\n",
      "Loaded data with 13 features\n",
      "Temporal features: ['time_features']\n",
      "Static features: ['coordinates', 'elevation']\n",
      "Time series features: ['air_temperature', 'clearsky_ghi', 'cloud_type', 'ghi', 'nighttime_mask', 'relative_humidity', 'solar_zenith_angle', 'surface_albedo', 'total_precipitable_water', 'wind_speed']\n",
      "Dataset dimensions: 8760 timesteps, 105 locations\n",
      "Dataset contains 917280 possible samples\n",
      "Loaded normalized data from data/processed/val_normalized.h5\n",
      "Loaded normalized data file (1/1): data/processed/val_normalized.h5\n",
      "Loaded data with 13 features\n",
      "Temporal features: ['time_features']\n",
      "Static features: ['coordinates', 'elevation']\n",
      "Time series features: ['air_temperature', 'clearsky_ghi', 'cloud_type', 'ghi', 'nighttime_mask', 'relative_humidity', 'solar_zenith_angle', 'surface_albedo', 'total_precipitable_water', 'wind_speed']\n",
      "Dataset dimensions: 8760 timesteps, 105 locations\n",
      "Dataset contains 917280 possible samples\n",
      "Loaded normalized data from data/processed/test_normalized.h5\n",
      "Loaded normalized data file (1/1): data/processed/test_normalized.h5\n",
      "Loaded data with 13 features\n",
      "Temporal features: ['time_features']\n",
      "Static features: ['coordinates', 'elevation']\n",
      "Time series features: ['air_temperature', 'clearsky_ghi', 'cloud_type', 'ghi', 'nighttime_mask', 'relative_humidity', 'solar_zenith_angle', 'surface_albedo', 'total_precipitable_water', 'wind_speed']\n",
      "Dataset dimensions: 8784 timesteps, 105 locations\n",
      "Dataset contains 919800 possible samples\n",
      "static_features shape: torch.Size([64, 2])\n",
      "target shape: torch.Size([64])\n",
      "temporal_features shape: torch.Size([64, 24, 8])\n",
      "air_temperature shape: torch.Size([64, 24])\n",
      "clearsky_ghi shape: torch.Size([64, 24])\n",
      "cloud_type shape: torch.Size([64, 24])\n",
      "ghi shape: torch.Size([64, 24])\n",
      "nighttime_mask shape: torch.Size([64, 24])\n",
      "relative_humidity shape: torch.Size([64, 24])\n",
      "solar_zenith_angle shape: torch.Size([64, 24])\n",
      "surface_albedo shape: torch.Size([64, 24])\n",
      "total_precipitable_water shape: torch.Size([64, 24])\n",
      "wind_speed shape: torch.Size([64, 24])\n",
      "nighttime shape: torch.Size([64, 24])\n"
     ]
    }
   ],
   "source": [
    "from utils.timeseriesdataset import TimeSeriesDataset\n",
    "\n",
    "LOOKBACK = 24\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TimeSeriesDataset(train_preprocessed_data_path, lookback=LOOKBACK)\n",
    "val_dataset = TimeSeriesDataset(val_preprocessed_data_path, lookback=LOOKBACK)\n",
    "test_dataset = TimeSeriesDataset(test_preprocessed_data_path, lookback=LOOKBACK)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Check sample batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "for key, value in sample_batch.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key} shape: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input dimensions determined from batch:\n",
      "  - Temporal dimension: 8\n",
      "  - Static dimension: 2\n"
     ]
    }
   ],
   "source": [
    "# Get a batch to determine input dimensions\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Method 1: Extract dimensions from a batch (more reliable)\n",
    "temporal_features = batch['temporal_features']\n",
    "static_features = batch['static_features']\n",
    "\n",
    "# Check if we have 3D temporal features (batch, seq_len, features)\n",
    "if len(temporal_features.shape) == 3:\n",
    "    temporal_dim = temporal_features.shape[2]\n",
    "else:\n",
    "    # Handle 2D temporal features (batch, features)\n",
    "    temporal_dim = temporal_features.shape[1]\n",
    "\n",
    "static_dim = static_features.shape[1]\n",
    "\n",
    "print(f\"  Input dimensions determined from batch:\")\n",
    "print(f\"  - Temporal dimension: {temporal_dim}\")\n",
    "print(f\"  - Static dimension: {static_dim}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "from utils.training_utils import train_model, evaluate_model\n",
    "from utils.wandb_utils import is_wandb_enabled, set_wandb_flag, set_keep_run_open\n",
    "from utils.model_utils import print_model_info\n",
    "\n",
    "# Default settings\n",
    "USE_WANDB = True\n",
    "WANDB_USERNAME = \"tin-hoang\"\n",
    "WANDB_PROJECT = \"EEEM073-Solar-Radiation\"\n",
    "\n",
    "# Enable wandb tracking\n",
    "set_wandb_flag(USE_WANDB)\n",
    "# Keep the wandb run open after training to continue logging evaluation plots\n",
    "set_keep_run_open(True)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "PATIENCE = 10\n",
    "LR = 0.001\n",
    "DEBUG_MODE = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Setup Experiment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_pipeline(model, train_loader, val_loader, test_loader, model_name, epochs=30, patience=5, lr=0.001):\n",
    "    \"\"\"\n",
    "    Run the experiment pipeline for a given model.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        train_loader: The training data loader.\n",
    "        val_loader: The validation data loader.\n",
    "        test_loader: The test data loader.\n",
    "        model_name: The name of the model.\n",
    "        epochs: The number of epochs to train the model.\n",
    "        patience: The number of epochs to wait before early stopping.\n",
    "        lr: The learning rate for the model.\n",
    "    \"\"\"\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    history = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        model_name=model_name,\n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        lr=lr,\n",
    "        debug_mode=DEBUG_MODE\n",
    "    )\n",
    "    training_plot = plot_training_history(history, model_name=model_name)\n",
    "\n",
    "    print(f\"Evaluating {model_name} model on validation set...\")\n",
    "    val_metrics = evaluate_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        scalers[f'{TARGET_VARIABLE}_scaler'],\n",
    "        model_name=f\"{model_name} - Validation\"\n",
    "    )\n",
    "    val_plot = plot_evaluation_metrics(val_metrics, model_name=f\"{model_name} - Validation\")\n",
    "\n",
    "    print(f\"\\nEvaluating {model_name} model on test set...\")\n",
    "    test_metrics = evaluate_model(\n",
    "        model,\n",
    "        test_loader,\n",
    "        scalers[f'{TARGET_VARIABLE}_scaler'],\n",
    "        model_name=f\"{model_name} - Test\"\n",
    "    )\n",
    "    test_plot = plot_evaluation_metrics(test_metrics, model_name=f\"{model_name} - Test\")\n",
    "\n",
    "    # Log the test plot to wandb\n",
    "    if is_wandb_enabled():\n",
    "        wandb.log({\"plots/history_plot\": wandb.Image(training_plot)})\n",
    "        wandb.log({\"plots/predictions_plot\": wandb.Image(val_plot)})\n",
    "        wandb.log({\"plots/predictions_plot\": wandb.Image(test_plot)})\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f'{model_name}_best.pt')\n",
    "\n",
    "    # Finish wandb run if it's still open\n",
    "    if is_wandb_enabled():\n",
    "        wandb.finish()\n",
    "\n",
    "    return history, val_metrics, test_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LSTMModel\n",
      "Total parameters: 215,777\n",
      "Trainable parameters: 215,777\n",
      "Non-trainable parameters: 0\n",
      "\n",
      "Model structure:\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(8, 128, num_layers=2, batch_first=True, dropout=0.3)\n",
      "  (bn_lstm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (static_proj): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=32, bias=True)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=160, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models.lstm import LSTMModel\n",
    "\n",
    "# Create LSTM model\n",
    "lstm_model = LSTMModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(lstm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model...\n",
      "track_experiment: USE_WANDB=True, wandb.run=None, keep_run_open=True\n",
      "Creating new wandb run for LSTM\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mLSTM\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Train the LSTM model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m lstm_history, lstm_val_metrics, lstm_test_metrics = \u001b[43mrun_experiment_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLR\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mrun_experiment_pipeline\u001b[39m\u001b[34m(model, train_loader, val_loader, test_loader, model_name, epochs, patience, lr)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mRun the experiment pipeline for a given model.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[33;03m    lr: The learning rate for the model.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEBUG_MODE\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m training_plot = plot_training_history(history, model_name=model_name)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m model on validation set...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Surrey/AI_and_Sustainability/EEEM073-Solar-Radiation/utils/wandb_utils.py:195\u001b[39m, in \u001b[36mtrack_experiment.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m run_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.datetime.now().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# Initialize wandb\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m \u001b[43mwandb\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWANDB_PROJECT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWANDB_USERNAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# Flag to indicate this wrapper created the run\u001b[39;00m\n\u001b[32m    203\u001b[39m wrapper_created_run = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/solar/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1650\u001b[39m, in \u001b[36minit\u001b[39m\u001b[34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[39m\n\u001b[32m   1647\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_settings.x_server_side_derived_summary:\n\u001b[32m   1648\u001b[39m             init_telemetry.feature.server_side_derived_summary = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwi\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_printer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wl:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/solar/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1116\u001b[39m, in \u001b[36m_WandbInit.init\u001b[39m\u001b[34m(self, settings, config, run_printer)\u001b[39m\n\u001b[32m   1113\u001b[39m run_start_handle = backend.interface.deliver_run_start(run)\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1115\u001b[39m     \u001b[38;5;66;03m# TODO: add progress to let user know we are doing something\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m     \u001b[43mrun_start_handle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait_or\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/solar/lib/python3.11/site-packages/wandb/sdk/mailbox/mailbox_handle.py:122\u001b[39m, in \u001b[36m_MailboxMappedHandle.wait_or\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait_or\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, timeout: \u001b[38;5;28mfloat\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m) -> _S:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait_or\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/solar/lib/python3.11/site-packages/wandb/sdk/mailbox/response_handle.py:88\u001b[39m, in \u001b[36mMailboxResponseHandle.wait_or\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m math.isfinite(timeout):\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTimeout must be finite or None.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[32m     90\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTimed out waiting for response on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._address\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     91\u001b[39m     )\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/threading.py:622\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    620\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/threading.py:324\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    326\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_name = \"LSTM\"\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_history, lstm_val_metrics, lstm_test_metrics = run_experiment_pipeline(\n",
    "    lstm_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 CNN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn_lstm import CNNLSTMModel\n",
    "\n",
    "# Create CNN-LSTM model\n",
    "cnn_lstm_model = CNNLSTMModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    hidden_dim=128,\n",
    "    num_filters=64,\n",
    "    kernel_size=3,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(cnn_lstm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CNN-LSTM\"\n",
    "\n",
    "# Train the LSTM model\n",
    "cnn_lstm_history, cnn_lstm_val_metrics, cnn_lstm_test_metrics = run_experiment_pipeline(\n",
    "    cnn_lstm_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Multi-Layer Perceptron (MLP) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mlp import MLPModel\n",
    "\n",
    "# Create MLP model\n",
    "mlp_model = MLPModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    hidden_dims=[256, 512, 256, 128],\n",
    "    dropout=0.3,\n",
    "    lookback=LOOKBACK\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(mlp_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MLP\"\n",
    "\n",
    "# Train the MLP model\n",
    "mlp_history, mlp_val_metrics, mlp_test_metrics = run_experiment_pipeline(\n",
    "    mlp_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Compare Models' Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import compare_models\n",
    "\n",
    "# Create a dictionary of model metrics\n",
    "model_metrics = {\n",
    "    'LSTM': lstm_test_metrics,\n",
    "    'CNN-LSTM': cnn_lstm_test_metrics,\n",
    "    'MLP': mlp_test_metrics\n",
    "}\n",
    "\n",
    "# Compare model performance on test set\n",
    "print(\"\\nTest Set Comparison:\")\n",
    "compare_models(model_metrics, dataset_name='Test Set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Model Comparison on Daytime/Nighttime/Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import compare_models_daytime_nighttime\n",
    "\n",
    "# Create a dictionary of model metrics\n",
    "model_metrics = {\n",
    "    'LSTM': lstm_test_metrics,\n",
    "    'CNN-LSTM': cnn_lstm_test_metrics,\n",
    "    'MLP': mlp_test_metrics\n",
    "}\n",
    "\n",
    "# Generate the comparison plot\n",
    "comparison_fig = compare_models_daytime_nighttime(model_metrics, dataset_name='Test Set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Time Series Predictions\n",
    "\n",
    "Visualize predictions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_over_time(models, model_names, data_loader, target_scaler, num_samples=200, start_idx=0):\n",
    "    \"\"\"\n",
    "    Plot time series predictions for multiple models with nighttime shading if available\n",
    "\n",
    "    Args:\n",
    "        models: List of PyTorch models\n",
    "        model_names: List of model names\n",
    "        data_loader: Data loader\n",
    "        target_scaler: Scaler for the target variable\n",
    "        num_samples: Number of consecutive time steps to plot\n",
    "        start_idx: Starting index in the dataset\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    # Get device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Collect data samples\n",
    "    all_batches = []\n",
    "    for batch in data_loader:\n",
    "        all_batches.append(batch)\n",
    "        if len(all_batches) * batch['target'].shape[0] > start_idx + num_samples:\n",
    "            break\n",
    "\n",
    "    # Combine batches into a single dataset\n",
    "    all_temporal = []\n",
    "    all_static = []\n",
    "    all_targets = []\n",
    "    all_nighttime = []\n",
    "    has_nighttime = False\n",
    "\n",
    "    for batch in all_batches:\n",
    "        all_temporal.append(batch['temporal_features'])\n",
    "        all_static.append(batch['static_features'])\n",
    "        all_targets.append(batch['target'])\n",
    "        # Check if nighttime data is available\n",
    "        if 'nighttime' in batch:\n",
    "            has_nighttime = True\n",
    "            all_nighttime.append(batch['nighttime'])\n",
    "\n",
    "    all_temporal = torch.cat(all_temporal, dim=0)\n",
    "    all_static = torch.cat(all_static, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    if has_nighttime:\n",
    "        all_nighttime = torch.cat(all_nighttime, dim=0)\n",
    "\n",
    "    # Get the subset for visualization\n",
    "    temporal = all_temporal[start_idx:start_idx+num_samples].to(device)\n",
    "    static = all_static[start_idx:start_idx+num_samples].to(device)\n",
    "    targets = all_targets[start_idx:start_idx+num_samples].cpu().numpy()\n",
    "\n",
    "    if has_nighttime:\n",
    "        nighttime = all_nighttime[start_idx:start_idx+num_samples].cpu().numpy()\n",
    "        # Ensure nighttime is a 1D array\n",
    "        if len(nighttime.shape) > 1:\n",
    "            nighttime = nighttime.flatten() if nighttime.shape[1] == 1 else nighttime[:,0]\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(temporal, static).cpu().numpy()\n",
    "            predictions.append(outputs)\n",
    "\n",
    "    # Inverse transform to original scale\n",
    "    y_true_orig = target_scaler.inverse_transform(targets.reshape(-1, 1)).flatten()\n",
    "    y_pred_orig_list = [target_scaler.inverse_transform(pred.reshape(-1, 1)).flatten() for pred in predictions]\n",
    "\n",
    "    # Create visualization\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # If we have nighttime data, shade those regions\n",
    "    if has_nighttime:\n",
    "        # Create mask for continuous nighttime periods\n",
    "        nighttime_bool = (nighttime > 0.5)\n",
    "\n",
    "        # Shade nighttime regions\n",
    "        night_regions = []\n",
    "        start = None\n",
    "        for i, is_night in enumerate(nighttime_bool):\n",
    "            if is_night and start is None:\n",
    "                start = i\n",
    "            elif not is_night and start is not None:\n",
    "                night_regions.append((start, i))\n",
    "                start = None\n",
    "\n",
    "        # Handle case where the last region is nighttime\n",
    "        if start is not None:\n",
    "            night_regions.append((start, len(nighttime_bool)))\n",
    "\n",
    "        # Plot nighttime regions\n",
    "        for start, end in night_regions:\n",
    "            ax.axvspan(start, end, alpha=0.2, color='gray', label='_nolegend_')\n",
    "\n",
    "        # Only add nighttime to the legend once\n",
    "        if night_regions:\n",
    "            # Add dummy entry for nighttime legend\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            handles.append(Patch(facecolor='gray', alpha=0.2))\n",
    "            labels.append('Nighttime')\n",
    "            ax.legend(handles, labels)\n",
    "\n",
    "    # Plot predictions\n",
    "    plt.plot(y_true_orig, 'k-', label='Actual GHI', linewidth=2)\n",
    "\n",
    "    colors = ['b-', 'r-', 'g-', 'm-', 'c-', 'y-']\n",
    "    for i, (pred, name) in enumerate(zip(y_pred_orig_list, model_names)):\n",
    "        plt.plot(pred, colors[i % len(colors)], label=f'{name} Predicted', alpha=0.7)\n",
    "\n",
    "    # Calculate and display error metrics for the visualization window\n",
    "    for i, (pred, name) in enumerate(zip(y_pred_orig_list, model_names)):\n",
    "        rmse = np.sqrt(np.mean((y_true_orig - pred) ** 2))\n",
    "        mae = np.mean(np.abs(y_true_orig - pred))\n",
    "\n",
    "        # Add metrics annotation\n",
    "        plt.annotate(f\"{name}: RMSE={rmse:.2f}, MAE={mae:.2f}\",\n",
    "                     xy=(0.02, 0.97 - 0.03*i),\n",
    "                     xycoords='axes fraction',\n",
    "                     fontsize=9,\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "\n",
    "    plt.title('GHI Predictions Over Time')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('GHI (W/mÂ²)')\n",
    "\n",
    "    # If we haven't added a legend yet (no nighttime data), add it now\n",
    "    if not has_nighttime or not night_regions:\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Plot time series predictions\n",
    "plot_predictions_over_time(\n",
    "    models=[lstm_model, cnn_lstm_model, mlp_model],\n",
    "    model_names=['LSTM', 'CNN-LSTM', 'MLP'],\n",
    "    data_loader=test_loader,\n",
    "    target_scaler=scalers[f'{TARGET_VARIABLE}_scaler'],\n",
    "    num_samples=72,\n",
    "    start_idx=0\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
