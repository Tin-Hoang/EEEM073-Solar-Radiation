{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28426bbb",
   "metadata": {},
   "source": [
    "# Solar Radiation Forecasting Models\n",
    "\n",
    "This notebook implements various deep learning models for Global Horizontal Irradiance (GHI) forecasting using time series weather data. The notebook explores four different model architectures for solar radiation prediction:\n",
    "\n",
    "1. **LSTM (Long Short-Term Memory)** - Specialized recurrent neural network architecture for sequential data\n",
    "2. **CNN-LSTM** - Hybrid model combining convolutional layers for feature extraction and LSTM for temporal pattern learning\n",
    "3. **MLP (Multi-Layer Perceptron)** - Standard feedforward neural network for regression tasks\n",
    "4. **1D CNN** - Convolutional neural network using 1D convolutions for time series processing\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "**IMPORTANT**: Before running this notebook, you must first run the `2_data_preprocessing.py` script to prepare the normalized data. This script generates the train, validation, and test datasets needed for model training and evaluation.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Data Loading** - Load preprocessed time series datasets\n",
    "2. **Model Training Setup** - Configure training parameters and utilities\n",
    "3. **Model Training** - Train multiple model architectures\n",
    "4. **Performance Evaluation** - Compare models using various metrics\n",
    "5. **Visualization** - Plot time series predictions and model comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de1efbb",
   "metadata": {},
   "source": [
    "# 1. Data Loading\n",
    "\n",
    "In this section, we load and prepare the preprocessed time series data for training our models. The data includes various weather features like temperature, wind speed, solar angles, etc., used to predict the Global Horizontal Irradiance (GHI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ff812",
   "metadata": {},
   "source": [
    "### 1.1 Import modules and define hyperparameters\n",
    "\n",
    "Here, we define hyperparameters for model training, including the lookback window, batch size, and selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829fd90",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload to mode 1\n",
    "%autoreload 2\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.dates as mdates\n",
    "# Local modules\n",
    "from utils.data_persistence import load_scalers\n",
    "from utils.plot_utils import plot_training_history, plot_evaluation_metrics\n",
    "from utils.training_utils import train_model, evaluate_model\n",
    "from utils.wandb_utils import is_wandb_enabled, set_wandb_flag, set_keep_run_open\n",
    "from utils.model_utils import print_model_info, save_model\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# ========== Model training hyperparameters =========\n",
    "PATIENCE = 10\n",
    "LR = 0.0001\n",
    "# Debug mode to test code. Set to False for actual training\n",
    "DEBUG_MODE = True\n",
    "\n",
    "if DEBUG_MODE:\n",
    "    # Local debug settings (to check if the code is working)\n",
    "    # Will only run 10 batches/epoch for 10 epochs\n",
    "    N_EPOCHS = 10\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = 4\n",
    "else:\n",
    "    # Remote server settings (to train the model, recommend using Otter lab machine)\n",
    "    N_EPOCHS = 30\n",
    "    BATCH_SIZE = 2 ** 13   # = 8192 samples\n",
    "    NUM_WORKERS = 16\n",
    "\n",
    "# ================= Wandb settings =============\n",
    "USE_WANDB = False\n",
    "WANDB_USERNAME = \"tin-hoang\"  # Your wandb username\n",
    "WANDB_PROJECT = \"EEEM073-Solar-Radiation\"  # Your wandb project name\n",
    "\n",
    "# =========== Time series hyperparameters ===========\n",
    "# Number of timesteps to look back when creating sequences\n",
    "LOOKBACK = 24\n",
    "\n",
    "# Choose features to use in modeling\n",
    "TIME_FEATURES = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos',\n",
    "            'month_sin', 'month_cos', 'dow_sin', 'dow_cos']\n",
    "SELECTED_FEATURES = [\n",
    "    'air_temperature',\n",
    "    'wind_speed',\n",
    "    'relative_humidity',\n",
    "    'cloud_type',      # Categorical feature\n",
    "    'solar_zenith_angle',\n",
    "    'clearsky_ghi',\n",
    "    'total_precipitable_water',\n",
    "    'surface_albedo',\n",
    "    'nighttime_mask',  # New field from preprocess_data\n",
    "    'cld_opd_dcomp',\n",
    "    'aod'\n",
    "]\n",
    "STATIC_FEATURES = ['latitude', 'longitude', 'elevation']\n",
    "# Target variable\n",
    "TARGET_VARIABLE = 'ghi'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaa8df4",
   "metadata": {},
   "source": [
    "### 1.2 Create PyTorch Datasets and DataLoaders\n",
    "\n",
    "Here, we set up the PyTorch data pipeline by creating custom datasets and DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf98cef",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Loading preprocessed data files generated from 2_data_preprocessing.py\n",
    "# These files contain normalized time series data split into train, validation, and test sets\n",
    "from utils.data_persistence import load_normalized_data\n",
    "\n",
    "TRAIN_PREPROCESSED_DATA_PATH = \"data/processed/train_normalized_20250430_145157.h5\"\n",
    "VAL_PREPROCESSED_DATA_PATH = \"data/processed/val_normalized_20250430_145205.h5\"\n",
    "TEST_PREPROCESSED_DATA_PATH = \"data/processed/test_normalized_20250430_145205.h5\"\n",
    "\n",
    "# Load sequences\n",
    "train_data, metadata = load_normalized_data(TRAIN_PREPROCESSED_DATA_PATH)\n",
    "\n",
    "SCALER_PATH = \"data/processed/scalers_20250430_145206.pkl\"\n",
    "scalers = load_scalers(SCALER_PATH)\n",
    "\n",
    "# Print metadata\n",
    "print(f\"Train set | Metadata: {metadata}\")\n",
    "# Print created time\n",
    "print(f\"Train set | Created time: {metadata['created_time'] if 'created_time' in metadata else 'No created time'}\")\n",
    "# Print raw files\n",
    "print(f\"Train set | Raw files: {metadata['raw_files'] if 'raw_files' in metadata else 'No raw files'}\")\n",
    "\n",
    "# Print data structure and shape\n",
    "print(f\"Train set | Data structure:\")\n",
    "for key, value in train_data.items():\n",
    "    print(f\"  {key} shape: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85402835",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Creating PyTorch datasets from preprocessed data\n",
    "# TimeSeriesDataset is a custom dataset class that formats the data for model training\n",
    "from utils.timeseriesdataset import TimeSeriesDataset\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TimeSeriesDataset(TRAIN_PREPROCESSED_DATA_PATH, lookback=LOOKBACK, target_field=TARGET_VARIABLE,\n",
    "                                 selected_features=SELECTED_FEATURES, include_target_history=False,\n",
    "                                 static_features=STATIC_FEATURES)\n",
    "val_dataset = TimeSeriesDataset(VAL_PREPROCESSED_DATA_PATH, lookback=LOOKBACK, target_field=TARGET_VARIABLE,\n",
    "                               selected_features=SELECTED_FEATURES, include_target_history=False,\n",
    "                               static_features=STATIC_FEATURES)\n",
    "test_dataset = TimeSeriesDataset(TEST_PREPROCESSED_DATA_PATH, lookback=LOOKBACK, target_field=TARGET_VARIABLE,\n",
    "                                selected_features=SELECTED_FEATURES, include_target_history=False,\n",
    "                                static_features=STATIC_FEATURES)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca615d5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Examining data dimensions to configure model architectures\n",
    "# Get a batch to determine input dimensions\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Check sample batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "for key, value in sample_batch.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key} shape: {value.shape}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"{key} length: {len(value)}\")\n",
    "\n",
    "# Extract dimensions from a batch (more reliable)\n",
    "temporal_features = batch['temporal_features']\n",
    "static_features = batch['static_features']\n",
    "TEMPORAL_FEATURES_SHAPE = list(temporal_features.shape)\n",
    "STATIC_FEATURES_SHAPE = list(static_features.shape)\n",
    "\n",
    "# Check if we have 3D temporal features (batch, seq_len, features)\n",
    "if len(temporal_features.shape) == 3:\n",
    "    temporal_dim = temporal_features.shape[2]\n",
    "else:\n",
    "    # Handle 2D temporal features (batch, features)\n",
    "    temporal_dim = temporal_features.shape[1]\n",
    "\n",
    "static_dim = static_features.shape[1]\n",
    "\n",
    "print(f\"  Input dimensions determined from batch:\")\n",
    "print(f\"  - Batch temporal_features shape: {TEMPORAL_FEATURES_SHAPE}\")\n",
    "print(f\"  - Batch static_features shape: {STATIC_FEATURES_SHAPE}\")\n",
    "print(f\"  - Temporal dimension: {temporal_dim}\")\n",
    "print(f\"  - Static dimension: {static_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763e896",
   "metadata": {},
   "source": [
    "## 2. Model Training Setup\n",
    "\n",
    "This section configures the training environment, including setting up experiment tracking, defining the training pipeline, and preparing evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ade54",
   "metadata": {},
   "source": [
    "## 2.1 Setting Wandb logging (optional)\n",
    "\n",
    "Weights & Biases (wandb) is used for experiment tracking. Here we configure whether to use wandb for logging model training progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable wandb tracking\n",
    "set_wandb_flag(USE_WANDB)\n",
    "# Keep the wandb run open after training to continue logging evaluation plots\n",
    "set_keep_run_open(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c32b23",
   "metadata": {},
   "source": [
    "## 2.2 Setup Experiment Pipeline\n",
    "\n",
    "We define a standardized pipeline for training and evaluating models. This function handles the entire workflow:\n",
    "1. Model training with early stopping (use train and val set)\n",
    "2. Evaluation on test data\n",
    "3. Saving model checkpoints\n",
    "4. Logging results to wandb (if enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf3109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_pipeline(model, train_loader, val_loader, test_loader, model_name, epochs=30, patience=5, lr=0.001):\n",
    "    \"\"\"\n",
    "    Run the experiment pipeline for a given model.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        train_loader: The training data loader.\n",
    "        val_loader: The validation data loader.\n",
    "        test_loader: The test data loader.\n",
    "        model_name: The name of the model.\n",
    "        epochs: The number of epochs to train the model.\n",
    "        patience: The number of epochs to wait before early stopping.\n",
    "        lr: The learning rate for the model.\n",
    "    \"\"\"\n",
    "    history, val_metrics, test_metrics = None, None, None\n",
    "\n",
    "    # Get the current config\n",
    "    CONFIG = {}\n",
    "    cur_globals = globals().copy()\n",
    "    for x in cur_globals:\n",
    "        # Only get the variables that are uppercase and not digits\n",
    "        if x.upper() == x and not x.startswith('_') and not x == \"CONFIG\":\n",
    "            CONFIG[x] = cur_globals[x]\n",
    "\n",
    "    try:\n",
    "        print(f\"Training {model_name} model...\")\n",
    "        history = train_model(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            model_name=model_name,\n",
    "            epochs=epochs,\n",
    "            patience=patience,\n",
    "            lr=lr,\n",
    "            target_scaler=scalers[f'{TARGET_VARIABLE}_scaler'],\n",
    "            config=CONFIG,\n",
    "            debug_mode=DEBUG_MODE,\n",
    "        )\n",
    "        training_plot = plot_training_history(history, model_name=model_name)\n",
    "\n",
    "        print(f\"\\nEvaluating {model_name} model on test set...\")\n",
    "        test_metrics = evaluate_model(\n",
    "            model,\n",
    "            test_loader,\n",
    "            scalers[f'{TARGET_VARIABLE}_scaler'],\n",
    "            model_name=f\"{model_name} - Test\",\n",
    "            debug_mode=DEBUG_MODE,\n",
    "        )\n",
    "        test_plot = plot_evaluation_metrics(test_metrics, model_name=f\"{model_name} - Test\")\n",
    "\n",
    "        # ========== Save Best Model Checkpoint ===========\n",
    "        checkpoint_dir = \"checkpoints\"\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "        # Generate timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        # Construct filename with timestamp and directory\n",
    "        model_filename = f\"{model_name}_best_{timestamp}.pt\"\n",
    "        model_path = os.path.join(checkpoint_dir, model_filename)\n",
    "\n",
    "        # Combine time keys and selected features for the complete temporal feature set\n",
    "        all_temporal_features = TIME_FEATURES + SELECTED_FEATURES\n",
    "\n",
    "        # Save the model with metadata using the new save_model function\n",
    "        save_model(\n",
    "            model=model,\n",
    "            filepath=model_path,\n",
    "            metadata={\n",
    "                \"model_name\": model_name,\n",
    "                \"timestamp\": timestamp,\n",
    "                \"train_metrics\": {\n",
    "                    \"final_train_loss\": history[\"train_loss\"][-1] if history and \"train_loss\" in history else None,\n",
    "                    \"final_train_mae\": history[\"train_mae\"][-1] if history and \"train_mae\" in history else None,\n",
    "                    \"final_val_loss\": history[\"val_loss\"][-1] if history and \"val_loss\" in history else None,\n",
    "                    \"final_val_mae\": history[\"val_mae\"][-1] if history and \"val_mae\" in history else None,\n",
    "                },\n",
    "                \"test_metrics\": {\n",
    "                    \"mse\": test_metrics[\"mse\"] if test_metrics else None,\n",
    "                    \"rmse\": test_metrics[\"rmse\"] if test_metrics else None,\n",
    "                    \"mae\": test_metrics[\"mae\"] if test_metrics else None,\n",
    "                    \"r2\": test_metrics[\"r2\"] if test_metrics else None,\n",
    "                }\n",
    "            },\n",
    "            temporal_features=all_temporal_features,\n",
    "            static_features=STATIC_FEATURES,\n",
    "            time_feature_keys=TIME_FEATURES,\n",
    "            config=CONFIG\n",
    "        )\n",
    "\n",
    "        print(f\"Best model saved to {model_path}\")\n",
    "\n",
    "        # Log saved model path to wandb if enabled\n",
    "        if is_wandb_enabled():\n",
    "            wandb.save(model_path)\n",
    "            print(f\"Saved model checkpoint logged to wandb: {model_path}\")\n",
    "            wandb.log({\"plots/history_plot\": wandb.Image(training_plot)})\n",
    "            wandb.log({\"plots/predictions_plot\": wandb.Image(test_plot)})\n",
    "\n",
    "    finally:\n",
    "        # Finish wandb run if it's still open\n",
    "        if is_wandb_enabled():\n",
    "            wandb.finish()\n",
    "\n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return history, val_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141cfead",
   "metadata": {},
   "source": [
    "# 3. Model Experiments\n",
    "\n",
    "This section implements and trains different neural network architectures for GHI forecasting. Each model is trained using the same pipeline for fair comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455b0b1",
   "metadata": {},
   "source": [
    "### 3.1 LSTM Model\n",
    "\n",
    "The Long Short-Term Memory (LSTM) network is a type of recurrent neural network well-suited for time series forecasting.\n",
    "It's designed to capture long-term dependencies in sequential data through specialized memory cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e6681c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from models.lstm import LSTMModel\n",
    "\n",
    "# Create LSTM model\n",
    "lstm_model = LSTMModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(lstm_model, temporal_features.shape, static_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b9af1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model_name = \"LSTM\"\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_history, lstm_val_metrics, lstm_test_metrics = run_experiment_pipeline(\n",
    "    lstm_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe79dad",
   "metadata": {},
   "source": [
    "### 3.2 CNN-LSTM Model\n",
    "\n",
    "The CNN-LSTM model combines convolutional layers with LSTM layers. The CNN component extracts features from the input data,\n",
    "which are then fed into LSTM layers to capture temporal patterns. This hybrid approach can be effective for time series with spatial correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f2865c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from models.cnn_lstm import CNNLSTMModel\n",
    "\n",
    "# Create CNN-LSTM model\n",
    "cnn_lstm_model = CNNLSTMModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    hidden_dim=128,\n",
    "    num_filters=64,\n",
    "    kernel_size=3,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(cnn_lstm_model, temporal_features.shape, static_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c6acb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model_name = \"CNN-LSTM\"\n",
    "\n",
    "# Train the LSTM model\n",
    "cnn_lstm_history, cnn_lstm_val_metrics, cnn_lstm_test_metrics = run_experiment_pipeline(\n",
    "    cnn_lstm_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ee50ec",
   "metadata": {},
   "source": [
    "### 3.3 Multi-Layer Perceptron (MLP) Model\n",
    "\n",
    "The MLP is a classic feedforward neural network with fully connected layers. While not specifically designed for sequential data,\n",
    "with proper feature engineering, MLPs can still perform well on time series tasks. Here, we flatten the temporal features to use with the MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3434c17",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from models.mlp import MLPModel\n",
    "\n",
    "# Create MLP model\n",
    "mlp_model = MLPModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    hidden_dims=[256, 512, 256, 128],\n",
    "    dropout=0.3,\n",
    "    lookback=LOOKBACK\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(mlp_model, temporal_features.shape, static_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c60ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MLP\"\n",
    "\n",
    "# Train the MLP model\n",
    "mlp_history, mlp_val_metrics, mlp_test_metrics = run_experiment_pipeline(\n",
    "    mlp_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63d887",
   "metadata": {},
   "source": [
    "### 3.4 1D CNN Model\n",
    "\n",
    "The 1D Convolutional Neural Network applies filters across the time dimension to extract patterns from sequential data.\n",
    "This approach is effective for capturing local patterns and can be computationally more efficient than recurrent networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e97ed",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from models.cnn1d import CNN1DModel\n",
    "\n",
    "# Create MLP model\n",
    "cnn1d_model = CNN1DModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    num_filters=[64, 128, 256],\n",
    "    kernel_sizes=[3, 3, 3],\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(cnn1d_model, temporal_features.shape, static_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"1D-CNN\"\n",
    "\n",
    "# Train the MLP model\n",
    "cnn1d_history, cnn1d_val_metrics, cnn1d_test_metrics = run_experiment_pipeline(\n",
    "    cnn1d_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ccf18",
   "metadata": {},
   "source": [
    "## 4. Model Comparison\n",
    "\n",
    "After training all models, we compare their performance to determine which architecture works best for GHI forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3843fa93",
   "metadata": {},
   "source": [
    "## 4.1 Compare Models' Performance\n",
    "\n",
    "This section compares the overall performance metrics (MSE, RMSE, MAE, WAPE, R²) and inference speed of all trained models on the test dataset.\n",
    "These metrics help us understand which model provides the most accurate predictions across the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9569a1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from utils.plot_utils import compare_models\n",
    "\n",
    "# Create a dictionary of model metrics\n",
    "model_metrics = {\n",
    "    'LSTM': lstm_test_metrics,\n",
    "    'CNN-LSTM': cnn_lstm_test_metrics,\n",
    "    'MLP': mlp_test_metrics,\n",
    "    '1D-CNN': cnn1d_test_metrics\n",
    "}\n",
    "# Drop the 'y_pred' and 'y_true' keys from the model metrics\n",
    "for model in model_metrics:\n",
    "    model_metrics[model].pop('y_pred', None)\n",
    "    model_metrics[model].pop('y_true', None)\n",
    "    model_metrics[model].pop('nighttime_mask', None)\n",
    "\n",
    "# Save model metrics to a json file for later use\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "json_file_path = f'plots/basic_model_metrics_{timestamp}.json'\n",
    "# Fix TypeError: Object of type float32 is not JSON serializable\n",
    "for model in model_metrics:\n",
    "    for key, value in model_metrics[model].items():\n",
    "        if isinstance(value, np.float32):\n",
    "            model_metrics[model][key] = float(value)\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(model_metrics, f)\n",
    "\n",
    "# Compare model performance on test set\n",
    "fig = compare_models(model_metrics, dataset_name='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c61b24",
   "metadata": {},
   "source": [
    "## 4.2 Model Comparison on Daytime/Nighttime/Overall\n",
    "\n",
    "Here we analyze model performance separately for daytime and nighttime periods. This is crucial for solar forecasting\n",
    "as prediction requirements and patterns differ significantly between day and night. The comparison helps identify\n",
    "which models perform better under different lighting conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aafb976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import compare_models_daytime_nighttime\n",
    "\n",
    "# Generate the comparison plot\n",
    "comparison_fig = compare_models_daytime_nighttime(model_metrics, dataset_name='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ded29c",
   "metadata": {},
   "source": [
    "## 5. Visualization and Analysis\n",
    "\n",
    "This section provides visual analysis of model predictions to better understand model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e436970",
   "metadata": {},
   "source": [
    "### 5.1 Time Series Predictions\n",
    "\n",
    "Visualize predictions over time to compare how each model tracks the actual GHI values. This visualization includes:\n",
    "- Actual GHI values (ground truth)\n",
    "- Predictions from each model\n",
    "- Nighttime periods shaded for context\n",
    "- Error metrics for the visualized time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2762dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_over_time(models, model_names, data_loader, target_scaler, num_samples=200, start_idx=0):\n",
    "    \"\"\"\n",
    "    Plot time series predictions for multiple models with nighttime shading if available\n",
    "\n",
    "    Args:\n",
    "        models: List of PyTorch models\n",
    "        model_names: List of model names\n",
    "        data_loader: Data loader\n",
    "        target_scaler: Scaler for the target variable\n",
    "        num_samples: Number of consecutive time steps to plot\n",
    "        start_idx: Starting index in the dataset\n",
    "    \"\"\"\n",
    "    # Get device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Collect data samples\n",
    "    all_batches = []\n",
    "    for batch in data_loader:\n",
    "        all_batches.append(batch)\n",
    "        if len(all_batches) * batch['target'].shape[0] > start_idx + num_samples:\n",
    "            break\n",
    "\n",
    "    # Combine batches into a single dataset\n",
    "    all_temporal = []\n",
    "    all_static = []\n",
    "    all_targets = []\n",
    "    all_nighttime = []\n",
    "    all_time_index_local = []\n",
    "    has_nighttime = False\n",
    "    has_time_index_local = False\n",
    "\n",
    "    for batch in all_batches:\n",
    "        all_temporal.append(batch['temporal_features'])\n",
    "        all_static.append(batch['static_features'])\n",
    "        all_targets.append(batch['target'])\n",
    "        # Check if nighttime data is available\n",
    "        if 'nighttime_mask' in batch:\n",
    "            has_nighttime = True\n",
    "            all_nighttime.append(batch['nighttime_mask'])\n",
    "        # Check if time_index_local is available\n",
    "        if 'time_index_local' in batch:\n",
    "            has_time_index_local = True\n",
    "            # Store the time index values as they are\n",
    "            if isinstance(batch['time_index_local'], list):\n",
    "                all_time_index_local.extend(batch['time_index_local'])\n",
    "            else:\n",
    "                all_time_index_local.append(batch['time_index_local'])\n",
    "\n",
    "    all_temporal = torch.cat(all_temporal, dim=0)\n",
    "    all_static = torch.cat(all_static, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    if has_nighttime:\n",
    "        all_nighttime = torch.cat(all_nighttime, dim=0)\n",
    "\n",
    "    # Get the subset for visualization\n",
    "    temporal = all_temporal[start_idx:start_idx+num_samples].to(device)\n",
    "    static = all_static[start_idx:start_idx+num_samples].to(device)\n",
    "    targets = all_targets[start_idx:start_idx+num_samples].cpu().numpy()\n",
    "\n",
    "    if has_nighttime:\n",
    "        nighttime = all_nighttime[start_idx:start_idx+num_samples].cpu().numpy()\n",
    "        # Ensure nighttime is a 1D array\n",
    "        if len(nighttime.shape) > 1:\n",
    "            nighttime = nighttime.flatten() if nighttime.shape[1] == 1 else nighttime[:,0]\n",
    "\n",
    "    # Get time index for x-axis if available\n",
    "    x_values = None\n",
    "    if has_time_index_local and len(all_time_index_local) >= start_idx + num_samples:\n",
    "        # Extract the time values for the plotting window\n",
    "        x_values = all_time_index_local[start_idx:start_idx+num_samples]\n",
    "\n",
    "        # Try to convert to datetime objects if they are strings\n",
    "        if isinstance(x_values[0], str):\n",
    "            try:\n",
    "                # Try different datetime formats\n",
    "                date_formats = ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M', '%Y-%m-%dT%H:%M:%S', '%Y%m%d%H%M%S']\n",
    "                for date_format in date_formats:\n",
    "                    try:\n",
    "                        x_values = [datetime.strptime(t, date_format) for t in x_values]\n",
    "                        print(f\"Successfully parsed dates with format: {date_format}\")\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "\n",
    "                # If we couldn't parse with any format, notify and use indices\n",
    "                if isinstance(x_values[0], str):\n",
    "                    print(f\"Could not parse date format: {x_values[0]}, using indices instead\")\n",
    "                    x_values = None\n",
    "\n",
    "            except (ValueError, TypeError) as e:\n",
    "                # If conversion fails, fall back to using indices\n",
    "                print(f\"Error converting time_index_local to datetime: {e}, using indices instead\")\n",
    "                x_values = None\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(temporal, static).cpu().numpy()\n",
    "            predictions.append(outputs)\n",
    "\n",
    "    # Inverse transform to original scale\n",
    "    y_true_orig = target_scaler.inverse_transform(targets.reshape(-1, 1)).flatten()\n",
    "    y_pred_orig_list = [target_scaler.inverse_transform(pred.reshape(-1, 1)).flatten() for pred in predictions]\n",
    "\n",
    "    # Create visualization\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Define colors and line styles for predictions\n",
    "    colors = ['blue', 'red', 'green', 'magenta', 'cyan', 'orange']\n",
    "    line_styles = ['--', ':', '-.', '--', ':', '--']\n",
    "\n",
    "    # Set x-axis values based on availability of time_index_local\n",
    "    if x_values:\n",
    "        # Plot actual values with time index\n",
    "        actual_line, = plt.plot(x_values, y_true_orig, 'k-', label='Actual GHI', linewidth=2)\n",
    "\n",
    "        # Plot predictions with time index\n",
    "        pred_lines = []\n",
    "        handles = [actual_line]\n",
    "        labels = ['Actual GHI']\n",
    "\n",
    "        for i, (pred, name) in enumerate(zip(y_pred_orig_list, model_names)):\n",
    "            color = colors[i % len(colors)]\n",
    "            style = line_styles[i % len(line_styles)]\n",
    "            line, = plt.plot(x_values, pred, color=color, linestyle=style, label=f'{name} Predicted', alpha=0.7)\n",
    "            pred_lines.append(line)\n",
    "            handles.append(line)\n",
    "            labels.append(f'{name} Predicted')\n",
    "\n",
    "        # Format the x-axis to show dates properly\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "        plt.xticks(rotation=0)  # Make labels horizontal\n",
    "        fig.subplots_adjust(bottom=0.15)  # Adjust bottom margin for horizontal labels\n",
    "\n",
    "        # If we have nighttime data, shade those regions\n",
    "        if has_nighttime:\n",
    "            # Modify nighttime shading to work with datetime x-axis\n",
    "            nighttime_bool = (nighttime > 0.5)\n",
    "            night_regions = []\n",
    "            start = None\n",
    "            for i, is_night in enumerate(nighttime_bool):\n",
    "                if is_night and start is None:\n",
    "                    start = i\n",
    "                elif not is_night and start is not None:\n",
    "                    night_regions.append((start, i))\n",
    "                    start = None\n",
    "            if start is not None:\n",
    "                night_regions.append((start, len(nighttime_bool)))\n",
    "\n",
    "            for start, end in night_regions:\n",
    "                if start < len(x_values) and end <= len(x_values):\n",
    "                    ax.axvspan(x_values[start], x_values[min(end, len(x_values)-1)],\n",
    "                              alpha=0.2, color='gray', label='_nolegend_')\n",
    "    else:\n",
    "        # Use default integer indices for x-axis\n",
    "        actual_line, = plt.plot(y_true_orig, 'k-', label='Actual GHI', linewidth=2)\n",
    "\n",
    "        # Plot predictions and collect handles/labels\n",
    "        pred_lines = []\n",
    "        handles = [actual_line]\n",
    "        labels = ['Actual GHI']\n",
    "\n",
    "        for i, (pred, name) in enumerate(zip(y_pred_orig_list, model_names)):\n",
    "            color = colors[i % len(colors)]\n",
    "            style = line_styles[i % len(line_styles)]\n",
    "            line, = plt.plot(pred, color=color, linestyle=style, label=f'{name} Predicted', alpha=0.7)\n",
    "            pred_lines.append(line)\n",
    "            handles.append(line)\n",
    "            labels.append(f'{name} Predicted')\n",
    "\n",
    "        # If we have nighttime data, shade those regions\n",
    "        if has_nighttime:\n",
    "            nighttime_bool = (nighttime > 0.5)\n",
    "            night_regions = []\n",
    "            start = None\n",
    "            for i, is_night in enumerate(nighttime_bool):\n",
    "                if is_night and start is None:\n",
    "                    start = i\n",
    "                elif not is_night and start is not None:\n",
    "                    night_regions.append((start, i))\n",
    "                    start = None\n",
    "            if start is not None:\n",
    "                night_regions.append((start, len(nighttime_bool)))\n",
    "\n",
    "            for start, end in night_regions:\n",
    "                ax.axvspan(start, end, alpha=0.2, color='gray', label='_nolegend_')\n",
    "\n",
    "    # Add nighttime legend if applicable\n",
    "    if has_nighttime and len(night_regions) > 0:\n",
    "        night_patch = Patch(facecolor='gray', alpha=0.2, label='Nighttime')\n",
    "        handles.append(night_patch)\n",
    "        labels.append('Nighttime')\n",
    "\n",
    "    # Calculate and display error metrics for the visualization window\n",
    "    for i, (pred, name) in enumerate(zip(y_pred_orig_list, model_names)):\n",
    "        rmse = np.sqrt(np.mean((y_true_orig - pred) ** 2))\n",
    "        mae = np.mean(np.abs(y_true_orig - pred))\n",
    "        plt.annotate(f\"{name}: RMSE={rmse:.2f}, MAE={mae:.2f}\",\n",
    "                     xy=(0.02, 0.97 - 0.03*i),\n",
    "                     xycoords='axes fraction',\n",
    "                     fontsize=9,\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "\n",
    "    plt.title('GHI Predictions Over Time')\n",
    "    plt.xlabel('Time' if x_values else 'Time Step')\n",
    "    plt.ylabel('GHI (W/m²)')\n",
    "\n",
    "    # Set the legend with the correct handles and labels\n",
    "    plt.legend(handles, labels, loc='upper right')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    plt.savefig(f'plots/predictions_over_time_{timestamp}.png')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c433d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series predictions\n",
    "_ = plot_predictions_over_time(\n",
    "    models=[lstm_model, cnn_lstm_model, mlp_model, cnn1d_model],\n",
    "    model_names=['LSTM', 'CNN-LSTM', 'MLP', '1D-CNN'],\n",
    "    data_loader=test_loader,\n",
    "    target_scaler=scalers[f'{TARGET_VARIABLE}_scaler'],\n",
    "    num_samples=72,\n",
    "    start_idx=40\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
