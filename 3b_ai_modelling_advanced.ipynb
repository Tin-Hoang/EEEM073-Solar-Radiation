{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create PyTorch Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload to mode 2\n",
    "%autoreload 2\n",
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "\n",
    "from utils.data_persistence import load_scalers\n",
    "from utils.plot_utils import plot_training_history, plot_evaluation_metrics\n",
    "from utils.wandb_utils import setup_wandb\n",
    "from utils.training_utils import train_model, evaluate_model\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "# List of features to use\n",
    "AVAILABLE_FEATURES = [\n",
    "    'ghi',                     # Target variable\n",
    "    'air_temperature',         # Weather features\n",
    "    'wind_speed',\n",
    "    'relative_humidity',\n",
    "    'dew_point',\n",
    "    'surface_pressure',\n",
    "    'total_precipitable_water',\n",
    "    'cloud_type',              # Cloud features\n",
    "    'cloud_fill_flag',\n",
    "    'cld_opd_dcomp',\n",
    "    'cld_press_acha',\n",
    "    'cld_reff_dcomp',\n",
    "    'clearsky_ghi',            # Clear sky estimates\n",
    "    'clearsky_dni',\n",
    "    'clearsky_dhi',\n",
    "    'solar_zenith_angle',      # Solar geometry\n",
    "    'surface_albedo',          # Surface properties\n",
    "    'ozone',                   # Atmospheric properties\n",
    "    'aod',\n",
    "    'ssa',\n",
    "    'asymmetry',\n",
    "    'alpha'\n",
    "]\n",
    "\n",
    "# Choose features to use in modeling\n",
    "SELECTED_FEATURES = [\n",
    "    'air_temperature',\n",
    "    'wind_speed',\n",
    "    'relative_humidity',\n",
    "    'cloud_type',\n",
    "    'solar_zenith_angle',\n",
    "    'clearsky_ghi',\n",
    "    'total_precipitable_water',\n",
    "    'surface_albedo'\n",
    "]\n",
    "\n",
    "# Target variable\n",
    "TARGET_VARIABLE = 'ghi'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_persistence import load_normalized_data\n",
    "\n",
    "train_preprocessed_data_path = \"data/processed/train_normalized.h5\"\n",
    "val_preprocessed_data_path = \"data/processed/val_normalized.h5\"\n",
    "test_preprocessed_data_path = \"data/processed/test_normalized.h5\"\n",
    "\n",
    "# Load sequences\n",
    "train_data, metadata = load_normalized_data(train_preprocessed_data_path)\n",
    "\n",
    "scaler_path = \"data/processed/model_scalers.pkl\"\n",
    "scalers = load_scalers(scaler_path)\n",
    "\n",
    "# Print metadata\n",
    "print(f\"Train set | Metadata: {metadata}\")\n",
    "# Print created time\n",
    "print(f\"Train set | Created time: {metadata['created_time'] if 'created_time' in metadata else 'No created time'}\")\n",
    "# Print raw files\n",
    "print(f\"Train set | Raw files: {metadata['raw_files'] if 'raw_files' in metadata else 'No raw files'}\")\n",
    "\n",
    "# Print data structure and shape\n",
    "print(f\"Train set | Data structure:\")\n",
    "for key, value in train_data.items():\n",
    "    print(f\"  {key} shape: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.timeseriesdataset import TimeSeriesDataset\n",
    "\n",
    "LOOKBACK = 24\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TimeSeriesDataset(train_preprocessed_data_path, lookback=LOOKBACK)\n",
    "val_dataset = TimeSeriesDataset(val_preprocessed_data_path, lookback=LOOKBACK)\n",
    "test_dataset = TimeSeriesDataset(test_preprocessed_data_path, lookback=LOOKBACK)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Check sample batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "for key, value in sample_batch.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key} shape: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch to determine input dimensions\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Method 1: Extract dimensions from a batch (more reliable)\n",
    "temporal_features = batch['temporal_features']\n",
    "static_features = batch['static_features']\n",
    "\n",
    "# Check if we have 3D temporal features (batch, seq_len, features)\n",
    "if len(temporal_features.shape) == 3:\n",
    "    temporal_dim = temporal_features.shape[2]\n",
    "else:\n",
    "    # Handle 2D temporal features (batch, features)\n",
    "    temporal_dim = temporal_features.shape[1]\n",
    "\n",
    "static_dim = static_features.shape[1]\n",
    "\n",
    "print(f\"  Input dimensions determined from batch:\")\n",
    "print(f\"  - Temporal dimension: {temporal_dim}\")\n",
    "print(f\"  - Static dimension: {static_dim}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "from utils.training_utils import train_model, evaluate_model\n",
    "from utils.wandb_utils import is_wandb_enabled, set_wandb_flag, set_keep_run_open\n",
    "from utils.model_utils import print_model_info\n",
    "\n",
    "# Default settings\n",
    "USE_WANDB = True\n",
    "WANDB_USERNAME = \"tin-hoang\"\n",
    "WANDB_PROJECT = \"EEEM073-Solar-Radiation\"\n",
    "\n",
    "# Enable wandb tracking\n",
    "set_wandb_flag(USE_WANDB)\n",
    "# Keep the wandb run open after training to continue logging evaluation plots\n",
    "set_keep_run_open(True)\n",
    "\n",
    "# Training parameters - might need to adjust for more complex models\n",
    "N_EPOCHS = 5\n",
    "PATIENCE = 10\n",
    "LR = 0.0005  # Lower learning rate for advanced models\n",
    "DEBUG_MODE = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Setup Experiment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_pipeline(model, train_loader, val_loader, test_loader, model_name, epochs=30, patience=5, lr=0.001):\n",
    "    \"\"\"\n",
    "    Run the experiment pipeline for a given model.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        train_loader: The training data loader.\n",
    "        val_loader: The validation data loader.\n",
    "        test_loader: The test data loader.\n",
    "        model_name: The name of the model.\n",
    "        epochs: The number of epochs to train the model.\n",
    "        patience: The number of epochs to wait before early stopping.\n",
    "        lr: The learning rate for the model.\n",
    "    \"\"\"\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    history = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        model_name=model_name,\n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        lr=lr,\n",
    "        debug_mode=DEBUG_MODE\n",
    "    )\n",
    "    training_plot = plot_training_history(history, model_name=model_name)\n",
    "\n",
    "    print(f\"Evaluating {model_name} model on validation set...\")\n",
    "    val_metrics = evaluate_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        scalers[f'{TARGET_VARIABLE}_scaler'],\n",
    "        model_name=f\"{model_name} - Validation\"\n",
    "    )\n",
    "    val_plot = plot_evaluation_metrics(val_metrics, model_name=f\"{model_name} - Validation\")\n",
    "\n",
    "    print(f\"\\nEvaluating {model_name} model on test set...\")\n",
    "    test_metrics = evaluate_model(\n",
    "        model,\n",
    "        test_loader,\n",
    "        scalers[f'{TARGET_VARIABLE}_scaler'],\n",
    "        model_name=f\"{model_name} - Test\"\n",
    "    )\n",
    "    test_plot = plot_evaluation_metrics(test_metrics, model_name=f\"{model_name} - Test\")\n",
    "\n",
    "    # Log the test plot to wandb\n",
    "    if is_wandb_enabled():\n",
    "        wandb.log({\"plots/history_plot\": wandb.Image(training_plot)})\n",
    "        wandb.log({\"plots/predictions_plot\": wandb.Image(val_plot)})\n",
    "        wandb.log({\"plots/predictions_plot\": wandb.Image(test_plot)})\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f'{model_name}_best.pt')\n",
    "\n",
    "    # Finish wandb run if it's still open\n",
    "    if is_wandb_enabled():\n",
    "        wandb.finish()\n",
    "\n",
    "    return history, val_metrics, test_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Temporal Convolutional Networks (TCN) Model\n",
    "\n",
    "TCNs are specialized convolutional architectures for sequence modeling that combine the best of CNNs and RNNs. The key features include:\n",
    "\n",
    "- **Causal Convolutions**: Each output only depends on current and past inputs.\n",
    "- **Dilated Convolutions**: Captures larger effective history with fewer parameters.\n",
    "- **Residual Connections**: Helps with training deep networks and information flow.\n",
    "\n",
    "TCNs can capture long-range patterns in time series data efficiently, making them suitable for solar radiation forecasting where both short-term weather fluctuations and longer-term patterns matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tcn import TCNModel\n",
    "\n",
    "# Create TCN model\n",
    "tcn_model = TCNModel(\n",
    "    input_dim=temporal_dim,\n",
    "    static_dim=static_dim,\n",
    "    num_channels=[64, 128, 128, 64],  # Number of channels in each layer\n",
    "    kernel_size=3,                    # Size of the convolutional kernel\n",
    "    dropout=0.2,                      # Dropout rate\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(tcn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"TCN\"\n",
    "\n",
    "# Train the TCN model\n",
    "tcn_history, tcn_val_metrics, tcn_test_metrics = run_experiment_pipeline(\n",
    "    tcn_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Transformer Model\n",
    "\n",
    "Transformers revolutionized natural language processing and have been adapted for time series forecasting with impressive results. Their key advantages include:\n",
    "\n",
    "- **Self-Attention Mechanism**: Allows the model to weight the importance of different input time steps dynamically.\n",
    "- **Parallelization**: Can process the entire sequence in parallel, unlike RNNs.\n",
    "- **Long-range Dependencies**: Captures dependencies at arbitrary distances in the sequence.\n",
    "\n",
    "For solar forecasting, Transformers can identify complex temporal patterns across different time scales and account for both short-term and long-term relationships in the weather and solar data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transformer import TransformerModel\n",
    "\n",
    "# Create Transformer model\n",
    "transformer_model = TransformerModel(\n",
    "    input_dim=temporal_dim,           # Dimension of input features\n",
    "    static_dim=static_dim,            # Dimension of static features\n",
    "    d_model=128,                      # Transformer model dimension\n",
    "    nhead=8,                          # Number of attention heads\n",
    "    num_layers=4,                     # Number of transformer layers\n",
    "    dim_feedforward=512,              # Dimension of feedforward network\n",
    "    dropout=0.2,                      # Dropout rate\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(transformer_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Transformer\"\n",
    "\n",
    "# Train the Transformer model\n",
    "transformer_history, transformer_val_metrics, transformer_test_metrics = run_experiment_pipeline(\n",
    "    transformer_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR * 0.5  # Lower learning rate for transformer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Informer Model\n",
    "\n",
    "The Informer model is a recent advancement in time series forecasting that addresses the limitations of standard Transformer models for long sequence prediction. Key innovations include:\n",
    "\n",
    "- **ProbSparse Self-attention**: Reduces complexity from O(L²) to O(L log L) where L is sequence length.\n",
    "- **Self-attention Distilling**: Progressive downsampling of hidden states along the encoder.\n",
    "- **Generative Decoder**: Enables long sequence prediction with minimal compute.\n",
    "\n",
    "For solar radiation forecasting, Informer can efficiently capture daily, weekly, and seasonal patterns while focusing computational resources on the most informative timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.informer import InformerModel\n",
    "\n",
    "# Create Informer model\n",
    "informer_model = InformerModel(\n",
    "    input_dim=temporal_dim,           # Dimension of input features\n",
    "    static_dim=static_dim,            # Dimension of static features\n",
    "    d_model=128,                      # Model dimension\n",
    "    n_heads=8,                        # Number of attention heads\n",
    "    e_layers=3,                       # Number of encoder layers\n",
    "    d_ff=256,                         # Dimension of feedforward network\n",
    "    dropout=0.1,                      # Dropout rate\n",
    "    activation='gelu'                 # Activation function\n",
    ").to(device)\n",
    "\n",
    "# Print the model\n",
    "print_model_info(informer_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Informer\"\n",
    "\n",
    "# Train the Informer model with a lower learning rate\n",
    "informer_history, informer_val_metrics, informer_test_metrics = run_experiment_pipeline(\n",
    "    informer_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    model_name=model_name,\n",
    "    epochs=N_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    lr=LR * 0.3  # Lower learning rate for Informer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Compare Models' Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import compare_models\n",
    "\n",
    "# Create a dictionary of model metrics\n",
    "model_metrics = {\n",
    "    'TCN': tcn_test_metrics,\n",
    "    'Transformer': transformer_test_metrics,\n",
    "    'Informer': informer_test_metrics\n",
    "}\n",
    "\n",
    "# Compare model performance on test set\n",
    "print(\"\\nTest Set Comparison:\")\n",
    "compare_models(model_metrics, dataset_name='Test Set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Model Comparison on Daytime/Nighttime/Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import compare_models_daytime_nighttime\n",
    "\n",
    "# Create a dictionary of model metrics\n",
    "model_metrics = {\n",
    "    'TCN': tcn_test_metrics,\n",
    "    'Transformer': transformer_test_metrics,\n",
    "    'Informer': informer_test_metrics\n",
    "}\n",
    "\n",
    "# Generate the comparison plot\n",
    "comparison_fig = compare_models_daytime_nighttime(model_metrics, dataset_name='Test Set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Time Series Predictions\n",
    "\n",
    "Visualize predictions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_over_time(models, model_names, data_loader, target_scaler, num_samples=200, start_idx=0):\n",
    "    \"\"\"\n",
    "    Plot time series predictions for multiple models with nighttime shading if available\n",
    "\n",
    "    Args:\n",
    "        models: List of PyTorch models\n",
    "        model_names: List of model names\n",
    "        data_loader: Data loader\n",
    "        target_scaler: Scaler for the target variable\n",
    "        num_samples: Number of consecutive time steps to plot\n",
    "        start_idx: Starting index in the dataset\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    # Get device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Collect data samples\n",
    "    all_batches = []\n",
    "    for batch in data_loader:\n",
    "        all_batches.append(batch)\n",
    "        if len(all_batches) * batch['target'].shape[0] > start_idx + num_samples:\n",
    "            break\n",
    "\n",
    "    # Combine batches into a single dataset\n",
    "    all_temporal = []\n",
    "    all_static = []\n",
    "    all_targets = []\n",
    "    all_nighttime = []\n",
    "    has_nighttime = False\n",
    "\n",
    "    for batch in all_batches:\n",
    "        all_temporal.append(batch['temporal_features'])\n",
    "        all_static.append(batch['static_features'])\n",
    "        all_targets.append(batch['target'])\n",
    "        # Check if nighttime data is available\n",
    "        if 'nighttime' in batch:\n",
    "            has_nighttime = True\n",
    "            all_nighttime.append(batch['nighttime'])\n",
    "\n",
    "    all_temporal = torch.cat(all_temporal, dim=0)\n",
    "    all_static = torch.cat(all_static, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    if has_nighttime:\n",
    "        all_nighttime = torch.cat(all_nighttime, dim=0)\n",
    "\n",
    "    # Get the subset for visualization\n",
    "    temporal = all_temporal[start_idx:start_idx+num_samples].to(device)\n",
    "    static = all_static[start_idx:start_idx+num_samples].to(device)\n",
    "    targets = all_targets[start_idx:start_idx+num_samples].cpu().numpy()\n",
    "\n",
    "    if has_nighttime:\n",
    "        nighttime = all_nighttime[start_idx:start_idx+num_samples].cpu().numpy()\n",
    "        # Ensure nighttime is a 1D array\n",
    "        if len(nighttime.shape) > 1:\n",
    "            nighttime = nighttime.flatten() if nighttime.shape[1] == 1 else nighttime[:,0]\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(temporal, static).cpu().numpy()\n",
    "            predictions.append(outputs)\n",
    "\n",
    "    # Inverse transform to original scale\n",
    "    y_true_orig = target_scaler.inverse_transform(targets.reshape(-1, 1)).flatten()\n",
    "    y_pred_orig_list = [target_scaler.inverse_transform(pred.reshape(-1, 1)).flatten() for pred in predictions]\n",
    "\n",
    "    # Create visualization\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # If we have nighttime data, shade those regions\n",
    "    if has_nighttime:\n",
    "        # Create mask for continuous nighttime periods\n",
    "        nighttime_bool = (nighttime > 0.5)\n",
    "\n",
    "        # Shade nighttime regions\n",
    "        night_regions = []\n",
    "        start = None\n",
    "        for i, is_night in enumerate(nighttime_bool):\n",
    "            if is_night and start is None:\n",
    "                start = i\n",
    "            elif not is_night and start is not None:\n",
    "                night_regions.append((start, i))\n",
    "                start = None\n",
    "\n",
    "        # Handle case where the last region is nighttime\n",
    "        if start is not None:\n",
    "            night_regions.append((start, len(nighttime_bool)))\n",
    "\n",
    "        # Plot nighttime regions\n",
    "        for start, end in night_regions:\n",
    "            ax.axvspan(start, end, alpha=0.2, color='gray', label='_nolegend_')\n",
    "\n",
    "        # Only add nighttime to the legend once\n",
    "        if night_regions:\n",
    "            # Add dummy entry for nighttime legend\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            handles.append(Patch(facecolor='gray', alpha=0.2))\n",
    "            labels.append('Nighttime')\n",
    "            ax.legend(handles, labels)\n",
    "\n",
    "    # Plot predictions\n",
    "    plt.plot(y_true_orig, 'k-', label='Actual GHI', linewidth=2)\n",
    "\n",
    "    colors = ['b-', 'r-', 'g-', 'm-', 'c-', 'y-']\n",
    "    for i, (pred, name) in enumerate(zip(y_pred_orig_list, model_names)):\n",
    "        plt.plot(pred, colors[i % len(colors)], label=f'{name} Predicted', alpha=0.7)\n",
    "\n",
    "    # Calculate and display error metrics for the visualization window\n",
    "    for i, (pred, name) in enumerate(zip(y_pred_orig_list, model_names)):\n",
    "        rmse = np.sqrt(np.mean((y_true_orig - pred) ** 2))\n",
    "        mae = np.mean(np.abs(y_true_orig - pred))\n",
    "\n",
    "        # Add metrics annotation\n",
    "        plt.annotate(f\"{name}: RMSE={rmse:.2f}, MAE={mae:.2f}\",\n",
    "                     xy=(0.02, 0.97 - 0.03*i),\n",
    "                     xycoords='axes fraction',\n",
    "                     fontsize=9,\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "\n",
    "    plt.title('GHI Predictions Over Time')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('GHI (W/m²)')\n",
    "\n",
    "    # If we haven't added a legend yet (no nighttime data), add it now\n",
    "    if not has_nighttime or not night_regions:\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Plot time series predictions\n",
    "plot_predictions_over_time(\n",
    "    models=[tcn_model, transformer_model, informer_model],\n",
    "    model_names=['TCN', 'Transformer', 'Informer'],\n",
    "    data_loader=test_loader,\n",
    "    target_scaler=scalers[f'{TARGET_VARIABLE}_scaler'],\n",
    "    num_samples=72,\n",
    "    start_idx=0\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
