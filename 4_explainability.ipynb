{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf02926",
   "metadata": {},
   "source": [
    "# Model Explainability Example\n",
    "\n",
    "This notebook demonstrates how to use the `explainability` module to understand predictions from trained solar radiation forecasting models. It covers:\n",
    "\n",
    "1. Setting up parameters (model type, paths, etc.)\n",
    "2. Loading data and a pre-trained model.\n",
    "3. Creating an appropriate explainer (SHAP or Sensitivity Analyzer).\n",
    "4. Preparing data samples for explanation.\n",
    "5. Running the explanation process.\n",
    "6. Visualizing results (feature importance, sensitivity plots).\n",
    "\n",
    "**Note:** You need to provide paths to your trained model and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f38be",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a09ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload to mode 2\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "\n",
    "# Import project modules\n",
    "from utils.explainer import ShapExplainer, SensitivityAnalyzer\n",
    "from utils.timeseriesdataset import TimeSeriesDataset\n",
    "from utils.model_utils import load_model\n",
    "from utils.plot_utils import plot_predictions_over_time\n",
    "from utils.data_persistence import load_scalers, load_normalized_data\n",
    "\n",
    "# Configure plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "# Timestamp the plot\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd6961d",
   "metadata": {},
   "source": [
    "## 2. Configuration Parameters\n",
    "\n",
    "Set the parameters for the explanation process. These correspond to the command-line arguments in the original script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef198ff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "MODEL_PATH = 'checkpoints/Informer_best_20250430_214758.pt' # <<< --- IMPORTANT: Set path to your trained model file\n",
    "SCALER_PATH = 'data/processed/scalers_20250430_145206.pkl' # <<< --- IMPORTANT: Set path to your scaler file\n",
    "TRAIN_PREPROCESSED_DATA_PATH = 'data/processed/train_normalized_20250430_145157.h5' # <<< --- IMPORTANT: Set path to your train data file\n",
    "TEST_PREPROCESSED_DATA_PATH = 'data/processed/test_normalized_20250430_145205.h5' # <<< --- IMPORTANT: Set path to your test data file\n",
    "LOOKBACK = 24      # Lookback window used during model training\n",
    "BATCH_SIZE = 64    # Batch size for data loading\n",
    "N_SAMPLES = 50    # Number of explanation samples from the test set to use\n",
    "BACKGROUND_SIZE = 20  # Number of background samples from the training set to use\n",
    "OUTPUT_DIR = 'explainability' # Directory to save results\n",
    "SHAP_ALGORITHM = 'gradient' # SHAP algorithm ('kernel' = model agnostic, 'gradient' = Deep Learning)\n",
    "# ---\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Model Path: {MODEL_PATH}\")\n",
    "print(f\"Data Path: {TEST_PREPROCESSED_DATA_PATH}\")\n",
    "print(f\"Output Directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db4b508",
   "metadata": {},
   "source": [
    "## 3. Load Data and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310db54b",
   "metadata": {},
   "source": [
    "### 3.1 Load Model and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5234bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and metadata first\n",
    "print(f\"Loading model from {MODEL_PATH}...\")\n",
    "try:\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Let load_model handle the model class loading\n",
    "    model, model_metadata = load_model(MODEL_PATH, device=device)\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "    # Ensure model is on the correct device\n",
    "    model = model.to(device)\n",
    "    # Make sure model is in evaluation mode to disable batch norm statistics updates\n",
    "    model.eval()\n",
    "\n",
    "    # Extract feature information from model metadata\n",
    "    temporal_features = model_metadata.get('temporal_features', [])\n",
    "    static_features = model_metadata.get('static_features', [])\n",
    "    time_feature_keys = model_metadata.get('time_feature_keys', [])\n",
    "    target_field = model_metadata.get('target_field', 'ghi')\n",
    "    model_type = model_metadata.get('model_type', '')\n",
    "\n",
    "    # Print model summary\n",
    "    print(\"\\n===== Model Summary =====\")\n",
    "    print(model)\n",
    "    print(\"========================\\n\")\n",
    "\n",
    "    # Check and print input size info from metadata\n",
    "    input_size = model_metadata.get('input_size', None)\n",
    "    hidden_size = model_metadata.get('hidden_size', None)\n",
    "    print(f\"Model type: {model_type}\")\n",
    "    print(f\"Model input size from metadata: {input_size}\")\n",
    "    print(f\"Model hidden size from metadata: {hidden_size}\")\n",
    "    print(f\"Model expects time feature keys: {time_feature_keys}\")\n",
    "    print(f\"Model expects temporal features: {temporal_features}\")\n",
    "    print(f\"Model expects static features: {static_features}\")\n",
    "    print(f\"Model target field: {target_field}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file not found at {MODEL_PATH}. Please check the path.\")\n",
    "    raise  # Re-raise the exception\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Load data\n",
    "print(f\"Loading data from {TRAIN_PREPROCESSED_DATA_PATH}...\")\n",
    "try:\n",
    "    train_data_dict, data_metadata = load_normalized_data(TRAIN_PREPROCESSED_DATA_PATH)\n",
    "\n",
    "    nighttime_mask = train_data_dict.get('nighttime_mask')\n",
    "    if nighttime_mask is None:\n",
    "        print(\"Warning: 'nighttime_mask' not found in data. Cannot filter for daytime samples.\")\n",
    "        use_mask_filtering = False\n",
    "    else:\n",
    "        print(f\"Loaded nighttime_mask with shape: {nighttime_mask.shape}\")\n",
    "        use_mask_filtering = True\n",
    "\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {TRAIN_PREPROCESSED_DATA_PATH}. Please check the path.\")\n",
    "    raise # Re-raise the exception\n",
    "\n",
    "# Prepare test dataset for explanations\n",
    "print(f\"Preparing test TimeSeriesDataset with lookback={LOOKBACK}...\")\n",
    "test_dataset = TimeSeriesDataset(\n",
    "    preprocessed_data_path=TEST_PREPROCESSED_DATA_PATH,\n",
    "    lookback=LOOKBACK,\n",
    "    target_field=target_field,\n",
    "    time_feature_keys=time_feature_keys,\n",
    "    selected_features=temporal_features,\n",
    "    static_features=static_features,\n",
    "    lazy_loading=False,\n",
    "    include_target_history=False\n",
    ")\n",
    "\n",
    "# Prepare train dataset for background data\n",
    "print(f\"Preparing train TimeSeriesDataset with lookback={LOOKBACK}...\")\n",
    "train_dataset = TimeSeriesDataset(\n",
    "    preprocessed_data_path=TRAIN_PREPROCESSED_DATA_PATH,\n",
    "    lookback=LOOKBACK,\n",
    "    target_field=target_field,\n",
    "    time_feature_keys=time_feature_keys,\n",
    "    selected_features=temporal_features,\n",
    "    static_features=static_features,\n",
    "    lazy_loading=False,\n",
    "    include_target_history=False\n",
    ")\n",
    "\n",
    "# Create a dataloader from the dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(\"DataLoader created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae8aef",
   "metadata": {},
   "source": [
    "### 3.2 Visualize Model Predictions Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf3cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = load_scalers(SCALER_PATH)\n",
    "# Define target scaler from the data_metadata\n",
    "target_scaler = scaler.get(f'{target_field}_scaler')\n",
    "if target_scaler is None:\n",
    "    print(f\"Warning: No scaler found for target field '{target_field}'. Visualization may show scaled values.\")\n",
    "\n",
    "# Visualize the loaded model's predictions\n",
    "print(\"Generating predictions visualization...\")\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Create the visualization using the imported function\n",
    "viz_fig = plot_predictions_over_time(\n",
    "    models=[model],\n",
    "    model_names=[model_type],\n",
    "    data_loader=test_loader,\n",
    "    target_scaler=target_scaler,\n",
    "    num_samples=72,  # Adjust as needed\n",
    "    start_idx=0       # Adjust as needed\n",
    ")\n",
    "\n",
    "# Display the plot if in a notebook environment\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eedc1c",
   "metadata": {},
   "source": [
    "### 3.3 Check a Sample Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check a sample batch\n",
    "batch = next(iter(test_loader))\n",
    "\n",
    "# Check sample batch\n",
    "for key, value in batch.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key} shape: {value.shape}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"{key} length: {len(value)}\")\n",
    "\n",
    "# Extract dimensions from a batch (more reliable)\n",
    "sample_temporal_features = batch['temporal_features']\n",
    "sample_static_features = batch['static_features']\n",
    "TEMPORAL_FEATURES_SHAPE = list(sample_temporal_features.shape)\n",
    "STATIC_FEATURES_SHAPE = list(sample_static_features.shape)\n",
    "\n",
    "# Check if we have 3D temporal features (batch, seq_len, features)\n",
    "if len(sample_temporal_features.shape) == 3:\n",
    "    temporal_dim = sample_temporal_features.shape[2]\n",
    "else:\n",
    "    # Handle 2D temporal features (batch, features)\n",
    "    temporal_dim = sample_temporal_features.shape[1]\n",
    "\n",
    "static_dim = sample_static_features.shape[1]\n",
    "\n",
    "print(f\"  Input dimensions determined from batch:\")\n",
    "print(f\"  - Batch temporal_features shape: {TEMPORAL_FEATURES_SHAPE}\")\n",
    "print(f\"  - Batch static_features shape: {STATIC_FEATURES_SHAPE}\")\n",
    "print(f\"  - Temporal dimension: {temporal_dim}\")\n",
    "print(f\"  - Static dimension: {static_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e92038",
   "metadata": {},
   "source": [
    "## 4. Create Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a6968c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f\"Creating explainer for model type: {model_type}...\")\n",
    "explainer = ShapExplainer(\n",
    "    model=model,\n",
    "    feature_names=temporal_features,\n",
    "    static_feature_names=static_features\n",
    ")\n",
    "print(f\"Explainer created: {type(explainer).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f1b33",
   "metadata": {},
   "source": [
    "## 5. Prepare Background Data from Train Set and Samples from Test Set\n",
    "\n",
    "We'll use the training data for background samples (SHAP baseline distribution) and test data for explanation samples.\n",
    "This approach is more meaningful as it uses the distribution the model was trained on as the baseline.\n",
    "Using the full training set can be computationally expensive, especially for methods like KernelSHAP,\n",
    "so we select a subset of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8626a6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- Prepare background data from TRAIN set ---\n",
    "print(\"Preparing background data from TRAIN set...\")\n",
    "train_temporal_samples = []\n",
    "train_static_samples = []\n",
    "\n",
    "# Choose a subset of training samples for background data\n",
    "train_indices = np.random.choice(len(train_dataset), min(BACKGROUND_SIZE, len(train_dataset)), replace=False)\n",
    "\n",
    "# Extract samples from train dataset\n",
    "for idx in train_indices:\n",
    "    train_sample = train_dataset[idx]\n",
    "\n",
    "    # Get temporal features\n",
    "    x_temporal_tensor = train_sample.get('temporal_features')\n",
    "    if isinstance(x_temporal_tensor, torch.Tensor):\n",
    "        train_temporal_samples.append(x_temporal_tensor.cpu().numpy())\n",
    "    else:\n",
    "        train_temporal_samples.append(x_temporal_tensor)\n",
    "\n",
    "    # Get static features\n",
    "    x_static_tensor = train_sample.get('static_features')\n",
    "    if isinstance(x_static_tensor, torch.Tensor):\n",
    "        train_static_samples.append(x_static_tensor.cpu().numpy())\n",
    "    else:\n",
    "        train_static_samples.append(x_static_tensor)\n",
    "\n",
    "# Stack collected numpy arrays for background data\n",
    "train_temporal_array = np.stack(train_temporal_samples, axis=0)\n",
    "train_static_array = np.stack(train_static_samples, axis=0)\n",
    "\n",
    "print(f\"Prepared {train_temporal_array.shape[0]} background samples from training data.\")\n",
    "print(f\"Background temporal data shape: {train_temporal_array.shape}\")\n",
    "print(f\"Background static data shape: {train_static_array.shape}\")\n",
    "\n",
    "# --- Prepare samples to explain from TEST set ---\n",
    "print(f\"Preparing {N_SAMPLES} samples for explanation from TEST set...\")\n",
    "X_temporal_samples = []\n",
    "X_static_samples = []\n",
    "y_samples = []\n",
    "\n",
    "# Determine valid indices based on nighttime mask (if available)\n",
    "if use_mask_filtering:\n",
    "    print(\"Filtering samples using nighttime_mask...\")\n",
    "    # Assume mask shape aligns with n_timesteps, handle potential multi-location later if needed\n",
    "    # We need the mask value at the *target* time step, which is `start_index + lookback`\n",
    "    mask_for_targets = nighttime_mask[test_dataset.lookback:]\n",
    "\n",
    "    # Valid start indices are those where the corresponding target mask is False (daytime)\n",
    "    # Need to adjust indices based on potential multi-location structure if mask is 2D\n",
    "    if len(nighttime_mask.shape) == 1:\n",
    "        # Simple case: 1D mask (applies to all locations or single location)\n",
    "        valid_dataset_indices = [idx for idx in range(len(test_dataset))\n",
    "                                if not mask_for_targets[idx // test_dataset.n_locations]] # Get timestep index\n",
    "    elif len(nighttime_mask.shape) == 2 and nighttime_mask.shape[1] == test_dataset.n_locations:\n",
    "        # 2D mask (timesteps, locations)\n",
    "        valid_dataset_indices = [idx for idx in range(len(test_dataset))\n",
    "                                if not mask_for_targets[idx // test_dataset.n_locations, idx % test_dataset.n_locations]]\n",
    "    else:\n",
    "        print(f\"Warning: Unexpected nighttime_mask shape {nighttime_mask.shape}. Proceeding without filtering.\")\n",
    "        valid_dataset_indices = list(range(len(test_dataset)))\n",
    "\n",
    "    if not valid_dataset_indices:\n",
    "        raise ValueError(\"Error: No daytime samples found after filtering with nighttime_mask.\")\n",
    "    print(f\"Found {len(valid_dataset_indices)} valid daytime samples out of {len(test_dataset)} total.\")\n",
    "else:\n",
    "    print(\"Skipping nighttime filtering (mask not available or disabled).\")\n",
    "    valid_dataset_indices = list(range(len(test_dataset)))\n",
    "\n",
    "# Determine the number of samples to actually select\n",
    "num_available = len(valid_dataset_indices)\n",
    "num_to_select = min(N_SAMPLES, num_available)\n",
    "\n",
    "if num_to_select <= 0:\n",
    "    raise ValueError(f\"Error: Cannot select {N_SAMPLES} samples. Only {num_available} valid samples available.\")\n",
    "\n",
    "print(f\"Selecting {num_to_select} samples for explanation from {num_available} valid samples...\")\n",
    "\n",
    "# Randomly choose indices from the valid ones\n",
    "selected_indices = np.random.choice(valid_dataset_indices, num_to_select, replace=False)\n",
    "\n",
    "# Retrieve samples directly from the dataset using selected indices\n",
    "for idx in selected_indices:\n",
    "    sample = test_dataset[idx] # __getitem__ returns a dict\n",
    "\n",
    "    # Ensure sample components are tensors before converting to numpy\n",
    "    x_temporal_tensor = sample.get('temporal_features')\n",
    "    x_static_tensor = sample.get('static_features')\n",
    "    y_tensor = sample.get('target')\n",
    "\n",
    "    # Convert tensors to numpy arrays (move to CPU first if on GPU)\n",
    "    if isinstance(x_temporal_tensor, torch.Tensor):\n",
    "        X_temporal_samples.append(x_temporal_tensor.cpu().numpy())\n",
    "    else:\n",
    "        X_temporal_samples.append(x_temporal_tensor) # Assume already numpy or compatible\n",
    "\n",
    "    if isinstance(x_static_tensor, torch.Tensor):\n",
    "        X_static_samples.append(x_static_tensor.cpu().numpy())\n",
    "    else:\n",
    "        X_static_samples.append(x_static_tensor)\n",
    "\n",
    "    if isinstance(y_tensor, torch.Tensor):\n",
    "        y_samples.append(y_tensor.cpu().numpy())\n",
    "    else:\n",
    "        y_samples.append(y_tensor)\n",
    "\n",
    "# Stack collected numpy arrays\n",
    "if not X_temporal_samples:\n",
    "    print(\"Error: No samples collected after filtering and selection.\")\n",
    "else:\n",
    "    X_temporal_array = np.stack(X_temporal_samples, axis=0)\n",
    "    X_static_array = np.stack(X_static_samples, axis=0)\n",
    "    y_array = np.stack(y_samples, axis=0)\n",
    "\n",
    "    print(f\"Prepared {X_temporal_array.shape[0]} samples from test data for explanation.\")\n",
    "    print(f\"Test temporal data shape: {X_temporal_array.shape}\")\n",
    "    print(f\"Test static data shape: {X_static_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b09c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 6. Run SHAP Explanation and Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e9ba7d",
   "metadata": {},
   "source": [
    "### 6.1 SHAP Explanation - Feature Names Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c18d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which explainer type we're using and proceed accordingly\n",
    "print(f\"--- Running SHAP Explanation ({SHAP_ALGORITHM}) ---\")\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(f\"X_temporal_array shape: {X_temporal_array.shape}\")\n",
    "print(f\"X_static_array shape: {X_static_array.shape}\")\n",
    "\n",
    "# Extract shape information for feature naming\n",
    "if len(X_temporal_array.shape) == 3:  # (batch, sequence, features)\n",
    "    batch_size, seq_len, n_features = X_temporal_array.shape\n",
    "    print(f\"Detected shape: batch_size={batch_size}, seq_len={seq_len}, n_features={n_features}\")\n",
    "\n",
    "    # Create meaningful feature names by combining temporal feature names with time steps\n",
    "    feature_names_flat = []\n",
    "    for t in range(seq_len):\n",
    "        for feat_idx, feat_name in enumerate(temporal_features):\n",
    "            # Create more descriptive feature names with time indices\n",
    "            feature_names_flat.append(f\"{feat_name}_t-{seq_len-1-t}\")\n",
    "\n",
    "    # Add static feature names if available\n",
    "    if static_features is not None and len(static_features) > 0:\n",
    "        feature_names_flat.extend(static_features)\n",
    "        print(f\"Added {len(static_features)} static features to feature_names_flat\")\n",
    "\n",
    "    print(f\"Created {len(feature_names_flat)} feature names\")\n",
    "else:\n",
    "    print(f\"Data array shape: {X_temporal_array.shape}\")\n",
    "    n_features = len(temporal_features)\n",
    "    seq_len = X_temporal_array.shape[1] // n_features\n",
    "    print(f\"Inferred shape: seq_len={seq_len}, n_features={n_features}\")\n",
    "\n",
    "    # Create meaningful feature names\n",
    "    feature_names_flat = []\n",
    "    for t in range(seq_len):\n",
    "        for feat_idx, feat_name in enumerate(temporal_features):\n",
    "            feature_names_flat.append(f\"{feat_name}_t-{seq_len-1-t}\")\n",
    "\n",
    "    # Add static feature names if available\n",
    "    if static_features is not None and len(static_features) > 0:\n",
    "        feature_names_flat.extend(static_features)\n",
    "        print(f\"Added {len(static_features)} static features to feature_names_flat\")\n",
    "\n",
    "    print(f\"Created {len(feature_names_flat)} feature names\")\n",
    "\n",
    "# Calculate total number of features (temporal + static)\n",
    "total_features = len(feature_names_flat)\n",
    "print(f\"Total number of features (temporal + static): {total_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8bc89c",
   "metadata": {},
   "source": [
    "### 6.2 SHAP Explanation - Background Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b84f2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Use train data for background - no flattening needed since model forward handles this\n",
    "X_temporal_bg = train_temporal_array\n",
    "X_static_bg = train_static_array\n",
    "\n",
    "# Create the proper tuple format expected by initialize_explainer\n",
    "background_data = (X_temporal_bg, X_static_bg)\n",
    "\n",
    "print(f\"Initializing SHAP explainer with {SHAP_ALGORITHM} algorithm using {X_temporal_bg.shape[0]} background samples from TRAIN set...\")\n",
    "print(f\"Background data temporal shape: {X_temporal_bg.shape}\")\n",
    "print(f\"Background data static shape: {X_static_bg.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ebbde",
   "metadata": {},
   "source": [
    "### 6.3 SHAP Explanation - Model Wrapper Setup\n",
    "Define the custom model wrapper function that properly handles combined temporal and static features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa77cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model_wrapper(x_input, return_pytorch_tensor=False):\n",
    "    \"\"\"Custom wrapper for the model that handles combined temporal and static features.\n",
    "\n",
    "    Args:\n",
    "        x_input: Combined input data (temporal + static features), can be numpy array or PyTorch tensor\n",
    "        return_pytorch_tensor: If True, return PyTorch tensor (for GradientExplainer),\n",
    "                               otherwise return numpy array (for KernelExplainer)\n",
    "    \"\"\"\n",
    "    # Handle both numpy arrays and PyTorch tensors as input\n",
    "    if isinstance(x_input, torch.Tensor):\n",
    "        x_combined = x_input\n",
    "        is_pytorch_input = True\n",
    "    else:\n",
    "        # Ensure input is numpy array\n",
    "        x_combined = np.asarray(x_input)\n",
    "        is_pytorch_input = False\n",
    "\n",
    "        # Add batch dimension if input is 1D (single instance)\n",
    "        if x_combined.ndim == 1:\n",
    "            x_combined = x_combined.reshape(1, -1)\n",
    "            is_single_instance = True\n",
    "        else:\n",
    "            is_single_instance = False\n",
    "\n",
    "        # Create a tensor from input\n",
    "        x_combined = torch.tensor(x_combined, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Get shapes from global variables\n",
    "    batch_size = x_combined.shape[0]\n",
    "    n_temporal_features = len(temporal_features)\n",
    "    seq_len = LOOKBACK\n",
    "    n_static_features = len(static_features)\n",
    "\n",
    "    # Calculate total number of elements in combined features\n",
    "    total_temporal_elements = seq_len * n_temporal_features\n",
    "    total_elements = total_temporal_elements + n_static_features\n",
    "\n",
    "    # Validate input dimensions\n",
    "    if x_combined.shape[1] != total_elements:\n",
    "        raise ValueError(\n",
    "            f\"Input tensor dimension ({x_combined.shape[1]}) does not match expected \"\n",
    "            f\"({total_temporal_elements} + {n_static_features} = {total_elements}). \"\n",
    "            f\"Check LOOKBACK, temporal_features, and static_features.\"\n",
    "        )\n",
    "\n",
    "    # Split the combined input into temporal and static parts\n",
    "    x_temporal_flat = x_combined[:, :total_temporal_elements]\n",
    "    x_static = x_combined[:, total_temporal_elements:]\n",
    "\n",
    "    # Reshape temporal features to 3D\n",
    "    x_temporal = x_temporal_flat.reshape(batch_size, seq_len, n_temporal_features)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    if return_pytorch_tensor:\n",
    "        # For GradientExplainer mode - return tensor directly (with gradient tracking)\n",
    "        outputs = model(x_temporal, x_static)\n",
    "        # Ensure outputs have shape (batch_size, num_outputs)\n",
    "        if len(outputs.shape) == 1:\n",
    "            # If output is 1D (e.g., single output value per sample), add a dimension\n",
    "            outputs = outputs.unsqueeze(1)  # Add a dimension to make it (batch_size, 1)\n",
    "        return outputs\n",
    "    else:\n",
    "        # For KernelExplainer mode - return numpy array (no gradient tracking)\n",
    "        with torch.no_grad():\n",
    "            output = model(x_temporal, x_static)\n",
    "\n",
    "        # Return numpy array\n",
    "        result = output.cpu().numpy()\n",
    "\n",
    "        # --- Ensure output is at least 1D for SHAP ---\n",
    "        final_result = np.atleast_1d(result)\n",
    "\n",
    "        # SHAP KernelExplainer expects shape (n_outputs,) for single instance explanations\n",
    "        # or (batch_size, n_outputs) for batch explanations.\n",
    "        return final_result\n",
    "\n",
    "print(\"Updated custom model wrapper defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828127c0",
   "metadata": {},
   "source": [
    "### 6.4 SHAP Explanation - Prepare Explanation Data & Initialize Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Prepare Data for Explanation ---\n",
    "# Explain a subset of the samples (SHAP can be slow)\n",
    "explain_size = min(N_SAMPLES, X_temporal_array.shape[0])\n",
    "explain_indices = np.random.choice(X_temporal_array.shape[0], explain_size, replace=False)\n",
    "\n",
    "# Get temporal data for explanation\n",
    "X_temporal_explain = X_temporal_array[explain_indices]\n",
    "print(f\"Selected {explain_size} samples for explanation.\")\n",
    "print(f\"Explanation temporal data shape: {X_temporal_explain.shape}\")\n",
    "\n",
    "# Get corresponding static data (if available)\n",
    "X_static_explain = X_static_array[explain_indices]\n",
    "print(f\"Explanation static data shape: {X_static_explain.shape}\")\n",
    "\n",
    "# --- 2. Combine Temporal and Static Features for SHAP ---\n",
    "# Flatten temporal data\n",
    "batch_size, seq_len, n_features = X_temporal_explain.shape\n",
    "X_temporal_flat = X_temporal_explain.reshape(batch_size, -1)\n",
    "\n",
    "# Combine flattened temporal and static data\n",
    "X_combined_explain = np.concatenate([X_temporal_flat, X_static_explain], axis=1)\n",
    "print(f\"Combined explanation data shape: {X_combined_explain.shape}\")\n",
    "\n",
    "# Similarly, combine background data\n",
    "batch_size_bg, seq_len_bg, n_features_bg = X_temporal_bg.shape\n",
    "X_temporal_bg_flat = X_temporal_bg.reshape(batch_size_bg, -1)\n",
    "X_combined_bg = np.concatenate([X_temporal_bg_flat, X_static_bg], axis=1)\n",
    "print(f\"Combined background data shape: {X_combined_bg.shape}\")\n",
    "\n",
    "# --- 3. Set Wrapper & Initialize Explainer ---\n",
    "print(\"Setting custom model wrapper...\")\n",
    "explainer.set_custom_model_wrapper(custom_model_wrapper)\n",
    "\n",
    "# Initialize the explainer using the combined background data\n",
    "print(\"Initializing explainer...\")\n",
    "explainer.initialize_explainer(X_combined_bg, algorithm=SHAP_ALGORITHM)\n",
    "print(\"Explainer initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef51b3",
   "metadata": {},
   "source": [
    "### 6.5 SHAP Explanation - Calculate SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the combined explanation data created in the previous cell\n",
    "print(f\"Calculating SHAP values for {explain_size} samples... (This might take a while)\")\n",
    "\n",
    "# Calculate SHAP values using the combined data\n",
    "shap_values = explainer.explain_batch(X_combined_explain)\n",
    "print(f\"SHAP values calculated. SHAP values shape: {shap_values.shape}\")\n",
    "\n",
    "# When preparing for visualization, we'll need to separate the SHAP values for temporal and static features\n",
    "n_temporal_elements = seq_len * n_features\n",
    "n_static_elements = X_static_explain.shape[1]\n",
    "\n",
    "# Split SHAP values into temporal and static parts if needed for visualization\n",
    "if shap_values.shape[1] == n_temporal_elements + n_static_elements:\n",
    "    print(\"Splitting SHAP values into temporal and static components for visualization...\")\n",
    "    temporal_shap_values = shap_values[:, :n_temporal_elements]\n",
    "    static_shap_values = shap_values[:, n_temporal_elements:]\n",
    "    print(f\"Temporal SHAP values shape: {temporal_shap_values.shape}\")\n",
    "    print(f\"Static SHAP values shape: {static_shap_values.shape}\")\n",
    "else:\n",
    "    print(f\"Warning: SHAP values shape {shap_values.shape} doesn't match expected combined dimension {n_temporal_elements + n_static_elements}\")\n",
    "    temporal_shap_values = shap_values\n",
    "    static_shap_values = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca67d810",
   "metadata": {},
   "source": [
    "### 6.6 SHAP Explanation - Prepare Visualization Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization, prepare feature names for both temporal and static features\n",
    "print(\"Preparing visualization data...\")\n",
    "\n",
    "# Verify we have the correct feature names\n",
    "print(f\"Number of temporal features: {len(temporal_features)}\")\n",
    "print(f\"Number of static features: {len(static_features or [])}\")\n",
    "print(f\"Total number of feature names: {len(feature_names_flat)}\")\n",
    "\n",
    "# For visualization, we'll use the flattened temporal data and static data\n",
    "X_flat_for_viz = X_combined_explain\n",
    "shap_values_for_viz = shap_values\n",
    "\n",
    "# Verify dimensions match between data and feature names\n",
    "if len(feature_names_flat) != X_flat_for_viz.shape[1]:\n",
    "    print(f\"Warning: Mismatch between feature names ({len(feature_names_flat)}) and data dimension ({X_flat_for_viz.shape[1]})\")\n",
    "\n",
    "    # Calculate expected feature counts\n",
    "    temporal_features_count = len(temporal_features) * seq_len\n",
    "    static_features_count = len(static_features or [])\n",
    "    expected_total = temporal_features_count + static_features_count\n",
    "    print(f\"Expected feature breakdown: {temporal_features_count} temporal + {static_features_count} static = {expected_total}\")\n",
    "\n",
    "    # Adjust feature names list if needed\n",
    "    if len(feature_names_flat) > X_flat_for_viz.shape[1]:\n",
    "        print(f\"Truncating feature names from {len(feature_names_flat)} to {X_flat_for_viz.shape[1]}\")\n",
    "        feature_names_flat = feature_names_flat[:X_flat_for_viz.shape[1]]\n",
    "    else:\n",
    "        # If we have fewer feature names than columns, add generic names for the rest\n",
    "        print(f\"Adding generic names for missing features\")\n",
    "        for i in range(len(feature_names_flat), X_flat_for_viz.shape[1]):\n",
    "            feature_names_flat.append(f'feature_{i}')\n",
    "\n",
    "# For 3D visualizations (if needed later)\n",
    "if SHAP_ALGORITHM == 'gradient':\n",
    "    # For gradient algorithm, try to reshape temporal SHAP values back to 3D\n",
    "    try:\n",
    "        n_temporal_elements = seq_len * len(temporal_features)\n",
    "        if shap_values.shape[1] >= n_temporal_elements:\n",
    "            # Extract just the temporal part of SHAP values\n",
    "            temporal_shap_values = shap_values[:, :n_temporal_elements]\n",
    "            explain_size = temporal_shap_values.shape[0]\n",
    "            # Reshape temporal part to 3D\n",
    "            shap_values_3d = temporal_shap_values.reshape(explain_size, seq_len, len(temporal_features))\n",
    "            X_3d = X_temporal_explain\n",
    "            print(f\"Reshaped temporal SHAP values to 3D: {shap_values_3d.shape}\")\n",
    "\n",
    "            # If static features exist, extract their SHAP values too\n",
    "            if len(static_features or []) > 0:\n",
    "                static_shap_values = shap_values[:, n_temporal_elements:]\n",
    "                print(f\"Static SHAP values shape: {static_shap_values.shape}\")\n",
    "        else:\n",
    "            print(f\"Warning: SHAP values shape {shap_values.shape} doesn't have enough elements for temporal reshaping\")\n",
    "            shap_values_3d = None\n",
    "            X_3d = None\n",
    "    except Exception as e:\n",
    "        print(f\"Could not reshape temporal SHAP values to 3D: {e}\")\n",
    "        shap_values_3d = None\n",
    "        X_3d = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9651eff",
   "metadata": {},
   "source": [
    "### 6.7 SHAP Explanation - Create Summary Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SHAP Summary Plot\n",
    "print(\"Generating SHAP summary plot...\")\n",
    "plt.figure()\n",
    "\n",
    "# Ensure shap_values and X_flat match in dimensions and are properly shaped for summary_plot\n",
    "# If we get multi-dimensional arrays, we need to flatten them correctly\n",
    "if len(shap_values_for_viz.shape) > 2:\n",
    "    print(f\"Reshaping multi-dimensional SHAP values from {shap_values_for_viz.shape} to 2D\")\n",
    "    shap_values_for_viz = shap_values_for_viz.reshape(shap_values_for_viz.shape[0], -1)\n",
    "\n",
    "if len(X_flat_for_viz.shape) > 2:\n",
    "    print(f\"Reshaping multi-dimensional X_flat from {X_flat_for_viz.shape} to 2D\")\n",
    "    X_flat_for_viz = X_flat_for_viz.reshape(X_flat_for_viz.shape[0], -1)\n",
    "\n",
    "# Check if dimensions match\n",
    "if shap_values_for_viz.shape[1] != X_flat_for_viz.shape[1]:\n",
    "    print(f\"Warning: Mismatch between SHAP values shape {shap_values_for_viz.shape} and feature shape {X_flat_for_viz.shape}\")\n",
    "    # Adjust feature dimensions if needed\n",
    "    min_dim = min(shap_values_for_viz.shape[1], X_flat_for_viz.shape[1])\n",
    "    shap_values_for_viz = shap_values_for_viz[:, :min_dim]\n",
    "    X_flat_for_viz = X_flat_for_viz[:, :min_dim]\n",
    "    feature_names_flat = feature_names_flat[:min_dim]\n",
    "\n",
    "print(f\"Final shapes - SHAP values: {shap_values_for_viz.shape}, X_flat: {X_flat_for_viz.shape}, feature names: {len(feature_names_flat)}\")\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values_for_viz,\n",
    "    X_flat_for_viz,\n",
    "    feature_names=feature_names_flat,\n",
    "    max_display=20,\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'SHAP Summary Plot ({model_type.upper()})')\n",
    "plt.tight_layout()\n",
    "summary_plot_path = output_dir / f\"{model_type}_shap_summary_{timestamp}.png\"\n",
    "plt.savefig(summary_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"Summary plot saved to {summary_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde91568",
   "metadata": {},
   "source": [
    "### 6.8 SHAP Explanation - Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46bbabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature Importance Plot\n",
    "print(\"Generating feature importance plot...\")\n",
    "\n",
    "# Calculate mean absolute SHAP value for each feature\n",
    "# Ensure feature_importance is 1-dimensional\n",
    "feature_importance = np.abs(shap_values_for_viz).mean(axis=0)\n",
    "if len(feature_importance.shape) > 1:\n",
    "    print(f\"Flattening feature_importance from {feature_importance.shape}\")\n",
    "    feature_importance = feature_importance.flatten()\n",
    "\n",
    "print(f\"Feature importance shape: {feature_importance.shape}, feature names length: {len(feature_names_flat)}\")\n",
    "\n",
    "# Match feature names to importance values\n",
    "if len(feature_names_flat) > len(feature_importance):\n",
    "    print(f\"Truncating feature names from {len(feature_names_flat)} to {len(feature_importance)}\")\n",
    "    feature_names_adjusted = feature_names_flat[:len(feature_importance)]\n",
    "elif len(feature_names_flat) < len(feature_importance):\n",
    "    print(f\"Truncating importance values from {len(feature_importance)} to {len(feature_names_flat)}\")\n",
    "    feature_importance = feature_importance[:len(feature_names_flat)]\n",
    "    feature_names_adjusted = feature_names_flat\n",
    "else:\n",
    "    feature_names_adjusted = feature_names_flat\n",
    "\n",
    "# Create a new shap_values array that matches the expected format for plot_feature_importance\n",
    "# The function expects the original shap_values array to calculate the mean abs value internally\n",
    "shap_values_adjusted = np.zeros((shap_values_for_viz.shape[0], len(feature_names_adjusted)))\n",
    "for i in range(shap_values_for_viz.shape[0]):\n",
    "    shap_values_adjusted[i] = feature_importance  # Each row is the same\n",
    "\n",
    "# Now plot using the properly dimensioned arrays\n",
    "fig = explainer.plot_feature_importance(\n",
    "    shap_values=shap_values_adjusted,  # Pass adjusted shap values\n",
    "    feature_names=feature_names_adjusted,  # Pass matched feature names\n",
    "    max_display=20,\n",
    "    show=False,\n",
    "    title=f\"{model_type.upper()} Feature Importance (Mean |SHAP Value|)\"\n",
    ")\n",
    "importance_plot_path = output_dir / f\"{model_type}_feature_importance_{timestamp}.png\"\n",
    "fig.savefig(importance_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "print(f\"Feature importance plot saved to {importance_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd57ea",
   "metadata": {},
   "source": [
    "### 6.9 SHAP Explanation - Temporal Analysis (for Both Algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b69017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special temporal visualization that works for both gradient and kernel algorithms\n",
    "print(f\"Attempting temporal analysis for {SHAP_ALGORITHM} algorithm...\")\n",
    "\n",
    "# Check if we have 3D data for gradient algorithm\n",
    "has_3d_data = SHAP_ALGORITHM == 'gradient' and 'X_3d' in locals() and 'shap_values_3d' in locals()\n",
    "\n",
    "# For kernel algorithm, we need to reshape the flattened values back to 3D\n",
    "if SHAP_ALGORITHM == 'kernel' and not has_3d_data:\n",
    "    if len(X_temporal_explain.shape) == 3 and len(shap_values.shape) == 2:\n",
    "        # Get original 3D dimensions\n",
    "        batch_size, seq_len, n_features = X_temporal_explain.shape\n",
    "\n",
    "        # Check if shap_values can be reshaped to match\n",
    "        if shap_values.shape[1] == seq_len * n_features:\n",
    "            print(f\"Reshaping kernel SHAP values from {shap_values.shape} back to 3D ({batch_size}, {seq_len}, {n_features})\")\n",
    "            try:\n",
    "                # Reshape flattened SHAP values back to 3D for temporal analysis\n",
    "                shap_values_3d = shap_values.reshape(batch_size, seq_len, n_features)\n",
    "                X_3d = X_temporal_explain\n",
    "                has_3d_data = True\n",
    "                print(\"Successfully reshaped kernel SHAP values for temporal analysis\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reshaping kernel SHAP values: {e}\")\n",
    "                has_3d_data = False\n",
    "        else:\n",
    "            print(f\"Cannot reshape kernel SHAP values: dimensions don't match. SHAP values shape: {shap_values.shape}, expected features: {seq_len * n_features}\")\n",
    "            has_3d_data = False\n",
    "    else:\n",
    "        print(f\"Cannot perform temporal analysis with kernel algorithm: input or SHAP values not in expected format\")\n",
    "        print(f\"X_temporal_explain shape: {X_temporal_explain.shape}, shap_values shape: {shap_values.shape}\")\n",
    "        has_3d_data = False\n",
    "\n",
    "# Generate temporal visualization if we have 3D data (either from gradient or reshaped kernel)\n",
    "if has_3d_data:\n",
    "    print(\"Generating temporal analysis plots...\")\n",
    "\n",
    "    # Calculate feature importance across time steps\n",
    "    batch_size, seq_len, n_features = shap_values_3d.shape\n",
    "    temporal_importance = np.abs(shap_values_3d).mean(axis=0)  # Shape: (seq_len, n_features)\n",
    "    print(f\"Temporal importance shape: {temporal_importance.shape}, should be ({seq_len}, {n_features})\")\n",
    "\n",
    "    # Create a plot showing feature importance across time steps\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Create a heatmap of temporal importance\n",
    "    plt.imshow(temporal_importance.T, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Mean |SHAP Value|')\n",
    "\n",
    "    # Set axis labels and ticks\n",
    "    plt.xlabel('Time Steps (t-n)')\n",
    "    plt.ylabel('Features')\n",
    "    # X-axis ticks are time steps from past to present\n",
    "    time_labels = [f't-{seq_len-1-i}' for i in range(seq_len)]\n",
    "    plt.xticks(range(seq_len), time_labels, rotation=45)\n",
    "    # Y-axis ticks are feature names\n",
    "    plt.yticks(range(n_features), temporal_features)\n",
    "\n",
    "    plt.title(f'{model_type.upper()} Temporal Feature Importance ({SHAP_ALGORITHM.capitalize()})')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    temporal_plot_path = output_dir / f\"{model_type}_{SHAP_ALGORITHM}_temporal_importance_{timestamp}.png\"\n",
    "    plt.savefig(temporal_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(f\"Temporal analysis plot saved to {temporal_plot_path}\")\n",
    "\n",
    "    # Create line plots for top features across time\n",
    "    # Identify top N features based on overall importance\n",
    "    top_n = min(10, n_features)\n",
    "    # Calculate mean importance per feature across all time steps\n",
    "    feature_avg_importance = np.mean(temporal_importance, axis=0)  # Shape: (n_features,)\n",
    "    print(f\"Feature average importance shape: {feature_avg_importance.shape}\")\n",
    "    # Get indices of top N features by importance\n",
    "    top_features_idx = np.argsort(feature_avg_importance)[-top_n:]\n",
    "    print(f\"Top {top_n} feature indices: {top_features_idx}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create x-axis values for plotting - using integers from 0 to seq_len-1\n",
    "    x_values = np.arange(seq_len)\n",
    "\n",
    "    # Plot each top feature's importance over time\n",
    "    for i, feat_idx in enumerate(top_features_idx):\n",
    "        feat_name = temporal_features[feat_idx]\n",
    "        # Extract this feature's importance at each time step\n",
    "        importance_over_time = temporal_importance[:, feat_idx]\n",
    "        print(f\"Feature '{feat_name}' importance shape: {importance_over_time.shape}\")\n",
    "        # Plot this feature's line\n",
    "        plt.plot(x_values, importance_over_time, marker='o', linewidth=2, label=feat_name)\n",
    "\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Feature Importance (Mean |SHAP Value|)')\n",
    "    plt.title(f'Top {top_n} Features Importance Across Time ({SHAP_ALGORITHM.capitalize()})')\n",
    "    plt.xticks(x_values, time_labels)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    top_features_path = output_dir / f\"{model_type}_{SHAP_ALGORITHM}_top_features_temporal_{timestamp}.png\"\n",
    "    plt.savefig(top_features_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(f\"Top features temporal analysis saved to {top_features_path}\")\n",
    "else:\n",
    "    print(\"Skipping temporal analysis (requires 3D data structures)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bbdda3",
   "metadata": {},
   "source": [
    "### 7. Sensitivity Analysis (Alternative to SHAP Gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775fa2ef",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"--- Running Sensitivity Analysis ---\")\n",
    "\n",
    "# Initialize the sensitivity analyzer\n",
    "explainer = SensitivityAnalyzer(model, temporal_features, static_features)\n",
    "\n",
    "# Analyze feature sensitivity\n",
    "sensitivity_df = explainer.analyze_feature_sensitivity(\n",
    "    X_temporal_array,\n",
    "    X_static_array,\n",
    "    perturbation=0.1, # How much to perturb features\n",
    "    n_samples=min(10, X_temporal_array.shape[0]) # Number of samples to base analysis on\n",
    ")\n",
    "print(\"Sensitivity analysis complete.\")\n",
    "\n",
    "# Plot feature sensitivity\n",
    "print(\"Generating feature sensitivity plot...\")\n",
    "fig = explainer.plot_feature_sensitivity(\n",
    "    sensitivity_df,\n",
    "    max_display=50,\n",
    "    show=False,\n",
    "    title=f\"{model_type.upper()} Feature Sensitivity\"\n",
    ")\n",
    "sensitivity_plot_path = output_dir / f\"{model_type}_sensitivity.png\"\n",
    "fig.savefig(sensitivity_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "print(f\"Feature sensitivity plot saved to {sensitivity_plot_path}\")\n",
    "\n",
    "# Save sensitivity data\n",
    "sensitivity_csv_path = output_dir / f\"{model_type}_sensitivity.csv\"\n",
    "sensitivity_df.to_csv(sensitivity_csv_path, index=False)\n",
    "print(f\"Sensitivity data saved to {sensitivity_csv_path}\")\n",
    "print(\"Top 10 Features by Sensitivity:\")\n",
    "print(sensitivity_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
