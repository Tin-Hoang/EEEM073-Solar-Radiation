{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3876b590",
   "metadata": {},
   "source": [
    "# Model Explainability Example\n",
    "\n",
    "This notebook demonstrates how to use the `explainability` module to understand predictions from trained solar radiation forecasting models. It covers:\n",
    "\n",
    "1. Setting up parameters (model type, paths, etc.)\n",
    "2. Loading data and a pre-trained model.\n",
    "3. Creating an appropriate explainer (SHAP or Sensitivity Analyzer).\n",
    "4. Preparing data samples for explanation.\n",
    "5. Running the explanation process.\n",
    "6. Visualizing results (feature importance, sensitivity plots).\n",
    "\n",
    "**Note:** You need to provide paths to your trained model and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81c8cf",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload to mode 2\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "\n",
    "# Import project modules\n",
    "from utils.explainer import ShapExplainer, SensitivityAnalyzer\n",
    "from utils.timeseriesdataset import TimeSeriesDataset\n",
    "from utils.model_utils import load_model\n",
    "from utils.plot_utils import plot_predictions_over_time\n",
    "from utils.data_persistence import load_scalers, load_normalized_data\n",
    "\n",
    "# Configure plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "# Timestamp the plot\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d580910",
   "metadata": {},
   "source": [
    "## 2. Configuration Parameters\n",
    "\n",
    "Set the parameters for the explanation process. These correspond to the command-line arguments in the original script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e591abd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "MODEL_PATH = 'checkpoints/Informer_best_20250430_214758.pt' # <<< --- IMPORTANT: Set path to your trained model file\n",
    "SCALER_PATH = 'data/processed/scalers_20250430_145206.pkl' # <<< --- IMPORTANT: Set path to your scaler file\n",
    "TRAIN_PREPROCESSED_DATA_PATH = 'data/processed/train_normalized_20250430_145157.h5' # <<< --- IMPORTANT: Set path to your train data file\n",
    "TEST_PREPROCESSED_DATA_PATH = 'data/processed/test_normalized_20250430_145205.h5' # <<< --- IMPORTANT: Set path to your test data file\n",
    "LOOKBACK = 24      # Lookback window used during model training\n",
    "BATCH_SIZE = 64    # Batch size for data loading\n",
    "N_SAMPLES = 10    # Number of explanation samples from the test set to use\n",
    "BACKGROUND_SIZE = 20  # Number of background samples from the training set to use\n",
    "OUTPUT_DIR = 'explainability' # Directory to save results\n",
    "SHAP_ALGORITHM = 'kernel' # SHAP algorithm ('kernel', 'deep', 'gradient') - relevant only if using SHAP\n",
    "# ---\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Model Path: {MODEL_PATH}\")\n",
    "print(f\"Data Path: {TEST_PREPROCESSED_DATA_PATH}\")\n",
    "print(f\"Output Directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1398cbf",
   "metadata": {},
   "source": [
    "## 3. Load Data and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f04472",
   "metadata": {},
   "source": [
    "### 3.1 Load Model and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f959d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and metadata first\n",
    "print(f\"Loading model from {MODEL_PATH}...\")\n",
    "try:\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Let load_model handle the model class loading\n",
    "    model, model_metadata = load_model(MODEL_PATH, device=device)\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "    # Ensure model is on the correct device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Extract feature information from model metadata\n",
    "    temporal_features = model_metadata.get('temporal_features', [])\n",
    "    static_features = model_metadata.get('static_features', [])\n",
    "    time_feature_keys = model_metadata.get('time_feature_keys', [])\n",
    "    target_field = model_metadata.get('target_field', 'ghi')\n",
    "    model_type = model_metadata.get('model_type', '')\n",
    "\n",
    "    # Print model summary\n",
    "    print(\"\\n===== Model Summary =====\")\n",
    "    print(model)\n",
    "    print(\"========================\\n\")\n",
    "\n",
    "    # Check and print input size info from metadata\n",
    "    input_size = model_metadata.get('input_size', None)\n",
    "    hidden_size = model_metadata.get('hidden_size', None)\n",
    "    print(f\"Model type: {model_type}\")\n",
    "    print(f\"Model input size from metadata: {input_size}\")\n",
    "    print(f\"Model hidden size from metadata: {hidden_size}\")\n",
    "    print(f\"Model expects time feature keys: {time_feature_keys}\")\n",
    "    print(f\"Model expects temporal features: {temporal_features}\")\n",
    "    print(f\"Model expects static features: {static_features}\")\n",
    "    print(f\"Model target field: {target_field}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file not found at {MODEL_PATH}. Please check the path.\")\n",
    "    raise  # Re-raise the exception\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Load data\n",
    "print(f\"Loading data from {TRAIN_PREPROCESSED_DATA_PATH}...\")\n",
    "try:\n",
    "    train_data_dict, data_metadata = load_normalized_data(TRAIN_PREPROCESSED_DATA_PATH)\n",
    "\n",
    "    nighttime_mask = train_data_dict.get('nighttime_mask')\n",
    "    if nighttime_mask is None:\n",
    "        print(\"Warning: 'nighttime_mask' not found in data. Cannot filter for daytime samples.\")\n",
    "        use_mask_filtering = False\n",
    "    else:\n",
    "        print(f\"Loaded nighttime_mask with shape: {nighttime_mask.shape}\")\n",
    "        use_mask_filtering = True\n",
    "\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {TRAIN_PREPROCESSED_DATA_PATH}. Please check the path.\")\n",
    "    raise # Re-raise the exception\n",
    "\n",
    "# Prepare test dataset for explanations\n",
    "print(f\"Preparing test TimeSeriesDataset with lookback={LOOKBACK}...\")\n",
    "test_dataset = TimeSeriesDataset(\n",
    "    preprocessed_data_path=TEST_PREPROCESSED_DATA_PATH,\n",
    "    lookback=LOOKBACK,\n",
    "    target_field=target_field,\n",
    "    time_feature_keys=time_feature_keys,\n",
    "    selected_features=temporal_features,\n",
    "    static_features=static_features,\n",
    "    lazy_loading=False,\n",
    "    include_target_history=False\n",
    ")\n",
    "\n",
    "# Prepare train dataset for background data\n",
    "print(f\"Preparing train TimeSeriesDataset with lookback={LOOKBACK}...\")\n",
    "train_dataset = TimeSeriesDataset(\n",
    "    preprocessed_data_path=TRAIN_PREPROCESSED_DATA_PATH,\n",
    "    lookback=LOOKBACK,\n",
    "    target_field=target_field,\n",
    "    time_feature_keys=time_feature_keys,\n",
    "    selected_features=temporal_features,\n",
    "    static_features=static_features,\n",
    "    lazy_loading=False,\n",
    "    include_target_history=False\n",
    ")\n",
    "\n",
    "# Create a dataloader from the dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(\"DataLoader created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf5387",
   "metadata": {},
   "source": [
    "### 3.2 Visualize Model Predictions Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = load_scalers(SCALER_PATH)\n",
    "# Define target scaler from the data_metadata\n",
    "target_scaler = scaler.get(f'{target_field}_scaler')\n",
    "if target_scaler is None:\n",
    "    print(f\"Warning: No scaler found for target field '{target_field}'. Visualization may show scaled values.\")\n",
    "\n",
    "# Visualize the loaded model's predictions\n",
    "print(\"Generating predictions visualization...\")\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Create the visualization using the imported function\n",
    "viz_fig = plot_predictions_over_time(\n",
    "    models=[model],\n",
    "    model_names=[model_type],\n",
    "    data_loader=test_loader,\n",
    "    target_scaler=target_scaler,\n",
    "    num_samples=72,  # Adjust as needed\n",
    "    start_idx=0       # Adjust as needed\n",
    ")\n",
    "\n",
    "# Display the plot if in a notebook environment\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e127289d",
   "metadata": {},
   "source": [
    "### 3.3 Check a Sample Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2388ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check a sample batch\n",
    "batch = next(iter(test_loader))\n",
    "\n",
    "# Check sample batch\n",
    "for key, value in batch.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key} shape: {value.shape}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"{key} length: {len(value)}\")\n",
    "\n",
    "# Extract dimensions from a batch (more reliable)\n",
    "sample_temporal_features = batch['temporal_features']\n",
    "sample_static_features = batch['static_features']\n",
    "TEMPORAL_FEATURES_SHAPE = list(sample_temporal_features.shape)\n",
    "STATIC_FEATURES_SHAPE = list(sample_static_features.shape)\n",
    "\n",
    "# Check if we have 3D temporal features (batch, seq_len, features)\n",
    "if len(sample_temporal_features.shape) == 3:\n",
    "    temporal_dim = sample_temporal_features.shape[2]\n",
    "else:\n",
    "    # Handle 2D temporal features (batch, features)\n",
    "    temporal_dim = sample_temporal_features.shape[1]\n",
    "\n",
    "static_dim = sample_static_features.shape[1]\n",
    "\n",
    "print(f\"  Input dimensions determined from batch:\")\n",
    "print(f\"  - Batch temporal_features shape: {TEMPORAL_FEATURES_SHAPE}\")\n",
    "print(f\"  - Batch static_features shape: {STATIC_FEATURES_SHAPE}\")\n",
    "print(f\"  - Temporal dimension: {temporal_dim}\")\n",
    "print(f\"  - Static dimension: {static_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542accd1",
   "metadata": {},
   "source": [
    "## 4. Create Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed2353",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f\"Creating explainer for model type: {model_type}...\")\n",
    "explainer = ShapExplainer(\n",
    "    model=model,\n",
    "    feature_names=temporal_features,\n",
    "    static_feature_names=static_features\n",
    ")\n",
    "print(f\"Explainer created: {type(explainer).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38997dcc",
   "metadata": {},
   "source": [
    "## 5. Prepare Background Data from Train Set and Samples from Test Set\n",
    "\n",
    "We'll use the training data for background samples (SHAP baseline distribution) and test data for explanation samples.\n",
    "This approach is more meaningful as it uses the distribution the model was trained on as the baseline.\n",
    "Using the full training set can be computationally expensive, especially for methods like KernelSHAP,\n",
    "so we select a subset of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722abcac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- Prepare background data from TRAIN set ---\n",
    "print(\"Preparing background data from TRAIN set...\")\n",
    "train_temporal_samples = []\n",
    "train_static_samples = []\n",
    "\n",
    "# Choose a subset of training samples for background data\n",
    "train_indices = np.random.choice(len(train_dataset), min(BACKGROUND_SIZE, len(train_dataset)), replace=False)\n",
    "\n",
    "# Extract samples from train dataset\n",
    "for idx in train_indices:\n",
    "    train_sample = train_dataset[idx]\n",
    "\n",
    "    # Get temporal features\n",
    "    x_temporal_tensor = train_sample.get('temporal_features')\n",
    "    if isinstance(x_temporal_tensor, torch.Tensor):\n",
    "        train_temporal_samples.append(x_temporal_tensor.cpu().numpy())\n",
    "    else:\n",
    "        train_temporal_samples.append(x_temporal_tensor)\n",
    "\n",
    "    # Get static features\n",
    "    x_static_tensor = train_sample.get('static_features')\n",
    "    if isinstance(x_static_tensor, torch.Tensor):\n",
    "        train_static_samples.append(x_static_tensor.cpu().numpy())\n",
    "    else:\n",
    "        train_static_samples.append(x_static_tensor)\n",
    "\n",
    "# Stack collected numpy arrays for background data\n",
    "train_temporal_array = np.stack(train_temporal_samples, axis=0)\n",
    "train_static_array = np.stack(train_static_samples, axis=0)\n",
    "\n",
    "print(f\"Prepared {train_temporal_array.shape[0]} background samples from training data.\")\n",
    "print(f\"Background temporal data shape: {train_temporal_array.shape}\")\n",
    "print(f\"Background static data shape: {train_static_array.shape}\")\n",
    "\n",
    "# --- Prepare samples to explain from TEST set ---\n",
    "print(f\"Preparing {N_SAMPLES} samples for explanation from TEST set...\")\n",
    "X_temporal_samples = []\n",
    "X_static_samples = []\n",
    "y_samples = []\n",
    "\n",
    "# Determine valid indices based on nighttime mask (if available)\n",
    "if use_mask_filtering:\n",
    "    print(\"Filtering samples using nighttime_mask...\")\n",
    "    # Assume mask shape aligns with n_timesteps, handle potential multi-location later if needed\n",
    "    # We need the mask value at the *target* time step, which is `start_index + lookback`\n",
    "    mask_for_targets = nighttime_mask[test_dataset.lookback:]\n",
    "\n",
    "    # Valid start indices are those where the corresponding target mask is False (daytime)\n",
    "    # Need to adjust indices based on potential multi-location structure if mask is 2D\n",
    "    if len(nighttime_mask.shape) == 1:\n",
    "        # Simple case: 1D mask (applies to all locations or single location)\n",
    "        valid_dataset_indices = [idx for idx in range(len(test_dataset))\n",
    "                                if not mask_for_targets[idx // test_dataset.n_locations]] # Get timestep index\n",
    "    elif len(nighttime_mask.shape) == 2 and nighttime_mask.shape[1] == test_dataset.n_locations:\n",
    "        # 2D mask (timesteps, locations)\n",
    "        valid_dataset_indices = [idx for idx in range(len(test_dataset))\n",
    "                                if not mask_for_targets[idx // test_dataset.n_locations, idx % test_dataset.n_locations]]\n",
    "    else:\n",
    "        print(f\"Warning: Unexpected nighttime_mask shape {nighttime_mask.shape}. Proceeding without filtering.\")\n",
    "        valid_dataset_indices = list(range(len(test_dataset)))\n",
    "\n",
    "    if not valid_dataset_indices:\n",
    "        raise ValueError(\"Error: No daytime samples found after filtering with nighttime_mask.\")\n",
    "    print(f\"Found {len(valid_dataset_indices)} valid daytime samples out of {len(test_dataset)} total.\")\n",
    "else:\n",
    "    print(\"Skipping nighttime filtering (mask not available or disabled).\")\n",
    "    valid_dataset_indices = list(range(len(test_dataset)))\n",
    "\n",
    "# Determine the number of samples to actually select\n",
    "num_available = len(valid_dataset_indices)\n",
    "num_to_select = min(N_SAMPLES, num_available)\n",
    "\n",
    "if num_to_select <= 0:\n",
    "    raise ValueError(f\"Error: Cannot select {N_SAMPLES} samples. Only {num_available} valid samples available.\")\n",
    "\n",
    "print(f\"Selecting {num_to_select} samples for explanation from {num_available} valid samples...\")\n",
    "\n",
    "# Randomly choose indices from the valid ones\n",
    "selected_indices = np.random.choice(valid_dataset_indices, num_to_select, replace=False)\n",
    "\n",
    "# Retrieve samples directly from the dataset using selected indices\n",
    "for idx in selected_indices:\n",
    "    sample = test_dataset[idx] # __getitem__ returns a dict\n",
    "\n",
    "    # Ensure sample components are tensors before converting to numpy\n",
    "    x_temporal_tensor = sample.get('temporal_features')\n",
    "    x_static_tensor = sample.get('static_features')\n",
    "    y_tensor = sample.get('target')\n",
    "\n",
    "    # Convert tensors to numpy arrays (move to CPU first if on GPU)\n",
    "    if isinstance(x_temporal_tensor, torch.Tensor):\n",
    "        X_temporal_samples.append(x_temporal_tensor.cpu().numpy())\n",
    "    else:\n",
    "        X_temporal_samples.append(x_temporal_tensor) # Assume already numpy or compatible\n",
    "\n",
    "    if isinstance(x_static_tensor, torch.Tensor):\n",
    "        X_static_samples.append(x_static_tensor.cpu().numpy())\n",
    "    else:\n",
    "        X_static_samples.append(x_static_tensor)\n",
    "\n",
    "    if isinstance(y_tensor, torch.Tensor):\n",
    "        y_samples.append(y_tensor.cpu().numpy())\n",
    "    else:\n",
    "        y_samples.append(y_tensor)\n",
    "\n",
    "# Stack collected numpy arrays\n",
    "if not X_temporal_samples:\n",
    "    print(\"Error: No samples collected after filtering and selection.\")\n",
    "else:\n",
    "    X_temporal_array = np.stack(X_temporal_samples, axis=0)\n",
    "    X_static_array = np.stack(X_static_samples, axis=0)\n",
    "    y_array = np.stack(y_samples, axis=0)\n",
    "\n",
    "    print(f\"Prepared {X_temporal_array.shape[0]} samples from test data for explanation.\")\n",
    "    print(f\"Test temporal data shape: {X_temporal_array.shape}\")\n",
    "    print(f\"Test static data shape: {X_static_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ce799",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 6. Run SHAP Explanation and Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf98c98a",
   "metadata": {},
   "source": [
    "### 6.1 SHAP Explanation - Feature Names Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68786959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which explainer type we're using and proceed accordingly\n",
    "print(f\"--- Running SHAP Explanation ({SHAP_ALGORITHM}) ---\")\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(f\"X_temporal_array shape: {X_temporal_array.shape}\")\n",
    "if X_static_array is not None:\n",
    "    print(f\"X_static_array shape: {X_static_array.shape}\")\n",
    "\n",
    "# Extract shape information for feature naming\n",
    "if len(X_temporal_array.shape) == 3:  # (batch, sequence, features)\n",
    "    batch_size, seq_len, n_features = X_temporal_array.shape\n",
    "    print(f\"Detected shape: batch_size={batch_size}, seq_len={seq_len}, n_features={n_features}\")\n",
    "\n",
    "    # Create meaningful feature names by combining temporal feature names with time steps\n",
    "    feature_names_flat = []\n",
    "    for t in range(seq_len):\n",
    "        for feat_idx, feat_name in enumerate(temporal_features):\n",
    "            # Create more descriptive feature names with time indices\n",
    "            feature_names_flat.append(f\"{feat_name}_t-{seq_len-1-t}\")\n",
    "    print(f\"Created {len(feature_names_flat)} feature names\")\n",
    "else:\n",
    "    print(f\"Data array shape: {X_temporal_array.shape}\")\n",
    "    n_features = len(temporal_features)\n",
    "    seq_len = X_temporal_array.shape[1] // n_features\n",
    "    print(f\"Inferred shape: seq_len={seq_len}, n_features={n_features}\")\n",
    "\n",
    "    # Create meaningful feature names\n",
    "    feature_names_flat = []\n",
    "    for t in range(seq_len):\n",
    "        for feat_idx, feat_name in enumerate(temporal_features):\n",
    "            feature_names_flat.append(f\"{feat_name}_t-{seq_len-1-t}\")\n",
    "    print(f\"Created {len(feature_names_flat)} feature names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9d4fef",
   "metadata": {},
   "source": [
    "### 6.2 SHAP Explanation - Background Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13445111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train data for background - no flattening needed since model forward handles this\n",
    "X_temporal_bg = train_temporal_array\n",
    "X_static_bg = train_static_array\n",
    "\n",
    "# Create the proper tuple format expected by initialize_explainer\n",
    "background_data = (X_temporal_bg, X_static_bg)\n",
    "\n",
    "print(f\"Initializing SHAP explainer with {SHAP_ALGORITHM} algorithm using {X_temporal_bg.shape[0]} background samples from TRAIN set...\")\n",
    "print(f\"Background data temporal shape: {X_temporal_bg.shape}\")\n",
    "if X_static_bg is not None:\n",
    "    print(f\"Background data static shape: {X_static_bg.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf89a28",
   "metadata": {},
   "source": [
    "### 6.3 SHAP Explanation - Model Wrapper Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d111e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom model wrapper function\n",
    "# Note: This needs X_static_explain to be defined in the scope before this cell is run\n",
    "# We will define X_static_explain in the next step (6.4) and then initialize the explainer.\n",
    "# Make sure model is in evaluation mode to disable batch norm statistics updates\n",
    "model.eval()\n",
    "\n",
    "def custom_model_wrapper(x_input, return_pytorch_tensor=False):\n",
    "    \"\"\"Custom wrapper for the model that passes inputs directly to model, handling 1D/2D inputs.\n",
    "\n",
    "    Args:\n",
    "        x_input: Input data, can be numpy array or PyTorch tensor\n",
    "        return_pytorch_tensor: If True, return PyTorch tensor (for GradientExplainer),\n",
    "                              otherwise return numpy array (for KernelExplainer)\n",
    "    \"\"\"\n",
    "    # Handle both numpy arrays and PyTorch tensors as input\n",
    "    if isinstance(x_input, torch.Tensor):\n",
    "        x_tensor = x_input\n",
    "        is_pytorch_input = True\n",
    "    else:\n",
    "        # Ensure input is numpy array\n",
    "        x_input_np = np.asarray(x_input)\n",
    "        is_pytorch_input = False\n",
    "\n",
    "        # Add batch dimension if input is 1D (single instance)\n",
    "        if x_input_np.ndim == 1:\n",
    "            x_input_np = x_input_np.reshape(1, -1)\n",
    "            is_single_instance = True\n",
    "        else:\n",
    "            is_single_instance = False\n",
    "\n",
    "        # Create a tensor from input\n",
    "        x_tensor = torch.tensor(x_input_np, dtype=torch.float32).to(device)\n",
    "\n",
    "    # --- Reshape flattened input for the model ---\n",
    "    # SHAP passes flattened input (batch_size, seq_len * n_features) for KernelExplainer\n",
    "    # or already 3D input (batch_size, seq_len, n_features) for GradientExplainer\n",
    "    # Check if reshaping is needed\n",
    "    if len(x_tensor.shape) == 2 and x_tensor.shape[1] == len(temporal_features) * LOOKBACK:\n",
    "        # Input is flattened, reshape to 3D\n",
    "        batch_size = x_tensor.shape[0]\n",
    "        expected_n_temporal_features = len(temporal_features) # Get number of features from global scope\n",
    "        expected_seq_len = LOOKBACK # Get lookback/seq_len from global scope\n",
    "\n",
    "        # Check if the flattened dimension matches expectations\n",
    "        if x_tensor.shape[1] != expected_seq_len * expected_n_temporal_features:\n",
    "            raise ValueError(\n",
    "                f\"Input tensor flattened dimension ({x_tensor.shape[1]}) does not match \"\n",
    "                f\"expected ({expected_seq_len} * {expected_n_temporal_features}). Check LOOKBACK and temporal_features.\"\n",
    "            )\n",
    "\n",
    "        x_tensor_reshaped = x_tensor.reshape(batch_size, expected_seq_len, expected_n_temporal_features)\n",
    "    else:\n",
    "        # Input is already in expected shape\n",
    "        x_tensor_reshaped = x_tensor\n",
    "    # ---------------------------------------------\n",
    "\n",
    "    # Get static features if available\n",
    "    static_tensor = None\n",
    "    if X_static_array is not None:\n",
    "        # Important: we need to repeat static features for each row in x_tensor\n",
    "        # Get a slice of static features with the right size\n",
    "        # The batch_size here is determined by the input x_tensor, which might be different from the original explain batch\n",
    "        current_batch_size = x_tensor_reshaped.shape[0] # Use reshaped tensor's batch size\n",
    "\n",
    "        # Select the appropriate static features based on input indices\n",
    "        # If input x_input corresponds to rows k, k+1,... from the original dataset,\n",
    "        # we need static features for rows k, k+1, ...\n",
    "        # SHAP doesn't easily provide original indices, so we might need to rely on repetition\n",
    "        # or assume the order matches the original data slice used for explanation.\n",
    "\n",
    "        # Use the indices corresponding to the explanation data slice\n",
    "        # Ensure X_static_explain is defined before this function is called!\n",
    "        static_features_to_use = X_static_explain\n",
    "\n",
    "        # Repeat static features if the model wrapper receives a larger batch than available static data\n",
    "        # This usually happens during SHAP's background processing\n",
    "        if current_batch_size > static_features_to_use.shape[0]:\n",
    "            repeat_factor = (current_batch_size // static_features_to_use.shape[0]) + 1\n",
    "            expanded_static = np.repeat(static_features_to_use, repeat_factor, axis=0)\n",
    "            static_features_to_use = expanded_static[:current_batch_size]\n",
    "        elif current_batch_size < static_features_to_use.shape[0]:\n",
    "                # If processing a single instance or smaller batch, take the corresponding static features\n",
    "                # This assumes the order in x_input matches the order in X_temporal_explain\n",
    "                # If it's a single instance, take the first row (this might be an approximation)\n",
    "                if not is_pytorch_input and is_single_instance:\n",
    "                    static_features_to_use = static_features_to_use[[0], :] # Take first row, keep 2D\n",
    "                else: # Otherwise, take the first batch_size rows\n",
    "                    static_features_to_use = static_features_to_use[:current_batch_size]\n",
    "\n",
    "        static_tensor = torch.tensor(\n",
    "            static_features_to_use,\n",
    "            dtype=torch.float32\n",
    "        ).to(device)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    if return_pytorch_tensor:\n",
    "        # For GradientExplainer mode - return tensor directly (with gradient tracking)\n",
    "        outputs = model(x_tensor_reshaped, static_tensor)\n",
    "        # Ensure outputs have shape (batch_size, num_outputs)\n",
    "        if len(outputs.shape) == 1:\n",
    "            # If output is 1D (e.g., single output value per sample), add a dimension\n",
    "            outputs = outputs.unsqueeze(1)  # Add a dimension to make it (batch_size, 1)\n",
    "        return outputs\n",
    "    else:\n",
    "        # For KernelExplainer mode - return numpy array (no gradient tracking)\n",
    "        with torch.no_grad():\n",
    "            # Use the reshaped tensor here\n",
    "            output = model(x_tensor_reshaped, static_tensor)\n",
    "\n",
    "        # Return numpy array\n",
    "        result = output.cpu().numpy()\n",
    "\n",
    "        # --- Ensure output is at least 1D for SHAP ---\n",
    "        final_result = np.atleast_1d(result)\n",
    "\n",
    "        # SHAP KernelExplainer expects shape (n_outputs,) for single instance explanations\n",
    "        # or (batch_size, n_outputs) for batch explanations.\n",
    "        return final_result\n",
    "\n",
    "print(\"Custom model wrapper defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd890d",
   "metadata": {},
   "source": [
    "### 6.4 SHAP Explanation - Prepare Explanation Data & Initialize Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11315be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Prepare Data for Explanation ---\n",
    "# Explain a subset of the samples (SHAP can be slow)\n",
    "explain_size = min(N_SAMPLES, X_temporal_array.shape[0])\n",
    "explain_indices = np.random.choice(X_temporal_array.shape[0], explain_size, replace=False)\n",
    "\n",
    "# Get temporal data for explanation\n",
    "X_temporal_explain = X_temporal_array[explain_indices]\n",
    "print(f\"Selected {explain_size} samples for explanation.\")\n",
    "print(f\"Explanation temporal data shape: {X_temporal_explain.shape}\")\n",
    "\n",
    "# Get corresponding static data (if available)\n",
    "X_static_explain = X_static_array[explain_indices]\n",
    "print(f\"Explanation static data shape: {X_static_explain.shape}\")\n",
    "\n",
    "# --- 2. Set Wrapper & Initialize Explainer ---\n",
    "# custom_model_wrapper should be defined in the previous cell\n",
    "# Set the custom model wrapper (it now has access to X_static_explain)\n",
    "print(\"Setting custom model wrapper...\")\n",
    "explainer.set_custom_model_wrapper(custom_model_wrapper)\n",
    "\n",
    "# Prepare background data for explainer initialization\n",
    "# background_data tuple was defined in cell 6.2\n",
    "X_temporal_bg_init = background_data[0] # Extract temporal part\n",
    "# Flatten background temporal data if using KernelExplainer\n",
    "if SHAP_ALGORITHM == 'kernel' and len(X_temporal_bg_init.shape) == 3:\n",
    "    print(\"Flattening background temporal data for KernelExplainer initialization...\")\n",
    "    X_temporal_bg_init = X_temporal_bg_init.reshape(X_temporal_bg_init.shape[0], -1)\n",
    "    print(f\"Flattened background shape for init: {X_temporal_bg_init.shape}\")\n",
    "\n",
    "# Initialize the explainer using the (potentially flattened) background temporal data\n",
    "print(\"Initializing explainer...\")\n",
    "explainer.initialize_explainer((X_temporal_bg_init, background_data[1]), algorithm=SHAP_ALGORITHM)\n",
    "print(\"Explainer initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba366ea",
   "metadata": {},
   "source": [
    "### 6.5 SHAP Explanation - Calculate SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45650281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare explanation data tuple\n",
    "# Use the X_temporal_explain and X_static_explain defined above\n",
    "explain_data = (X_temporal_explain, X_static_explain)\n",
    "\n",
    "# Special preprocessing for KernelExplainer which requires 2D inputs\n",
    "# Use the variables defined in the previous cell\n",
    "if SHAP_ALGORITHM == 'kernel' and len(X_temporal_explain.shape) == 3:\n",
    "    print(\"Flattening temporal data for KernelExplainer (requires 2D input)...\")\n",
    "    X_temporal_flat = X_temporal_explain.reshape(X_temporal_explain.shape[0], -1)\n",
    "    # Recreate explain_data tuple with flattened temporal data\n",
    "    explain_data = (X_temporal_flat, X_static_explain)\n",
    "    print(f\"Flattened shape for KernelExplainer: {X_temporal_flat.shape}\")\n",
    "\n",
    "# Calculate SHAP values\n",
    "print(f\"Calculating SHAP values for {explain_size} samples... (This might take a while)\")\n",
    "shap_values = explainer.explain_batch(explain_data)\n",
    "print(f\"SHAP values calculated. SHAP values shape: {shap_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa68b0a",
   "metadata": {},
   "source": [
    "### 6.6 SHAP Explanation - Prepare Visualization Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1439cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization, we need to handle the data differently based on algorithm\n",
    "print(f\"Preparing visualization data for {SHAP_ALGORITHM} algorithm...\")\n",
    "\n",
    "if SHAP_ALGORITHM == 'gradient':\n",
    "    # For gradient algorithm, we try to preserve the 3D structure if possible\n",
    "    if len(X_temporal_explain.shape) == 3 and len(shap_values.shape) == 3:\n",
    "        print(f\"Using 3D SHAP values with shape {shap_values.shape} for temporal analysis\")\n",
    "        # Create a 3D-aware visualization\n",
    "\n",
    "        # For summary plot we still need to flatten data\n",
    "        X_flat = X_temporal_explain.reshape(explain_size, -1)\n",
    "        shap_values_flat = shap_values.reshape(explain_size, -1)\n",
    "\n",
    "        # Save the original 3D structure for possible time-based visualizations\n",
    "        X_3d = X_temporal_explain\n",
    "        shap_values_3d = shap_values\n",
    "\n",
    "        print(f\"Also created flattened representation - X_flat: {X_flat.shape}, shap_values_flat: {shap_values_flat.shape}\")\n",
    "    else:\n",
    "        print(f\"SHAP values shape: {shap_values.shape} doesn't match expected 3D structure, flattening data\")\n",
    "        # Fall back to flattening if structures don't match\n",
    "        X_flat = X_temporal_explain.reshape(explain_size, -1) if len(X_temporal_explain.shape) > 2 else X_temporal_explain\n",
    "        shap_values_flat = shap_values.reshape(explain_size, -1) if len(shap_values.shape) > 2 else shap_values\n",
    "else:\n",
    "    # For kernel algorithm, data is always flattened\n",
    "    if len(X_temporal_explain.shape) == 3:  # 3D data (batch, seq, features)\n",
    "        X_flat = X_temporal_explain.reshape(explain_size, -1)\n",
    "        shap_values_flat = shap_values.reshape(explain_size, -1)\n",
    "    elif len(X_temporal_explain.shape) > 3:  # e.g., CNN input (batch, seq, h, w)\n",
    "        X_flat = X_temporal_explain.reshape(explain_size, -1)\n",
    "        shap_values_flat = shap_values.reshape(explain_size, -1)\n",
    "        # Create meaningful feature names for flattened data if possible\n",
    "        # This part might need customization based on the exact CNN structure\n",
    "        feature_names_flat = [f'pixel_{i}' for i in range(X_flat.shape[1])]\n",
    "    else: # Already 2D data (batch, features)\n",
    "        X_flat = X_temporal_explain\n",
    "        shap_values_flat = shap_values\n",
    "\n",
    "# Add static features if they exist\n",
    "if X_static_array is not None:\n",
    "    # Use the actual static explain data from our tuple\n",
    "    print(\"Note: Static feature SHAP values might require model-specific handling.\")\n",
    "    # Example: Concatenate static features if explainer provides values for them\n",
    "    # X_flat = np.concatenate((X_flat, X_static_explain), axis=1)\n",
    "    # feature_names_flat += static_features\n",
    "    # shap_values_flat = np.concatenate((shap_values_flat, shap_values_static), axis=1) # If available\n",
    "\n",
    "# Ensure feature names match dimensions\n",
    "if len(feature_names_flat) != X_flat.shape[1]:\n",
    "    print(f\"Warning: Mismatch between number of feature names ({len(feature_names_flat)}) and data dimension ({X_flat.shape[1]}). Adjusting feature names.\")\n",
    "    # Fallback: generic feature names\n",
    "    feature_names_flat = [f'feature_{i}' for i in range(X_flat.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62863940",
   "metadata": {},
   "source": [
    "### 6.7 SHAP Explanation - Create Summary Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae20136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SHAP Summary Plot\n",
    "print(\"Generating SHAP summary plot...\")\n",
    "plt.figure()\n",
    "\n",
    "# Ensure shap_values and X_flat match in dimensions and are properly shaped for summary_plot\n",
    "# If we get multi-dimensional arrays, we need to flatten them correctly\n",
    "if len(shap_values_flat.shape) > 2:\n",
    "    print(f\"Reshaping multi-dimensional SHAP values from {shap_values_flat.shape} to 2D\")\n",
    "    shap_values_flat = shap_values_flat.reshape(shap_values_flat.shape[0], -1)\n",
    "\n",
    "if len(X_flat.shape) > 2:\n",
    "    print(f\"Reshaping multi-dimensional X_flat from {X_flat.shape} to 2D\")\n",
    "    X_flat = X_flat.reshape(X_flat.shape[0], -1)\n",
    "\n",
    "# Check if dimensions match\n",
    "if shap_values_flat.shape[1] != X_flat.shape[1]:\n",
    "    print(f\"Warning: Mismatch between SHAP values shape {shap_values_flat.shape} and feature shape {X_flat.shape}\")\n",
    "    # Adjust feature dimensions if needed\n",
    "    min_dim = min(shap_values_flat.shape[1], X_flat.shape[1])\n",
    "    shap_values_flat = shap_values_flat[:, :min_dim]\n",
    "    X_flat = X_flat[:, :min_dim]\n",
    "    feature_names_flat = feature_names_flat[:min_dim]\n",
    "\n",
    "print(f\"Final shapes - SHAP values: {shap_values_flat.shape}, X_flat: {X_flat.shape}, feature names: {len(feature_names_flat)}\")\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values_flat,\n",
    "    X_flat,\n",
    "    feature_names=feature_names_flat,\n",
    "    max_display=20,\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'SHAP Summary Plot ({model_type.upper()})')\n",
    "plt.tight_layout()\n",
    "summary_plot_path = output_dir / f\"{model_type}_shap_summary_{timestamp}.png\"\n",
    "plt.savefig(summary_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"Summary plot saved to {summary_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda9eada",
   "metadata": {},
   "source": [
    "### 6.8 SHAP Explanation - Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9054c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature Importance Plot\n",
    "print(\"Generating feature importance plot...\")\n",
    "\n",
    "# Calculate mean absolute SHAP value for each feature\n",
    "# Ensure feature_importance is 1-dimensional\n",
    "feature_importance = np.abs(shap_values_flat).mean(axis=0)\n",
    "if len(feature_importance.shape) > 1:\n",
    "    print(f\"Flattening feature_importance from {feature_importance.shape}\")\n",
    "    feature_importance = feature_importance.flatten()\n",
    "\n",
    "print(f\"Feature importance shape: {feature_importance.shape}, feature names length: {len(feature_names_flat)}\")\n",
    "\n",
    "# Match feature names to importance values\n",
    "if len(feature_names_flat) > len(feature_importance):\n",
    "    print(f\"Truncating feature names from {len(feature_names_flat)} to {len(feature_importance)}\")\n",
    "    feature_names_adjusted = feature_names_flat[:len(feature_importance)]\n",
    "elif len(feature_names_flat) < len(feature_importance):\n",
    "    print(f\"Truncating importance values from {len(feature_importance)} to {len(feature_names_flat)}\")\n",
    "    feature_importance = feature_importance[:len(feature_names_flat)]\n",
    "    feature_names_adjusted = feature_names_flat\n",
    "else:\n",
    "    feature_names_adjusted = feature_names_flat\n",
    "\n",
    "# Create a new shap_values array that matches the expected format for plot_feature_importance\n",
    "# The function expects the original shap_values array to calculate the mean abs value internally\n",
    "shap_values_adjusted = np.zeros((explain_size, len(feature_names_adjusted)))\n",
    "for i in range(explain_size):\n",
    "    shap_values_adjusted[i] = feature_importance  # Each row is the same\n",
    "\n",
    "# Now plot using the properly dimensioned arrays\n",
    "fig = explainer.plot_feature_importance(\n",
    "    shap_values=shap_values_adjusted,  # Pass adjusted shap values\n",
    "    feature_names=feature_names_adjusted,  # Pass matched feature names\n",
    "    max_display=20,\n",
    "    show=False,\n",
    "    title=f\"{model_type.upper()} Feature Importance (Mean |SHAP Value|)\"\n",
    ")\n",
    "importance_plot_path = output_dir / f\"{model_type}_feature_importance_{timestamp}.png\"\n",
    "fig.savefig(importance_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "print(f\"Feature importance plot saved to {importance_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c407e0",
   "metadata": {},
   "source": [
    "### 6.9 SHAP Explanation - Temporal Analysis (for Both Algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a20147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special temporal visualization that works for both gradient and kernel algorithms\n",
    "print(f\"Attempting temporal analysis for {SHAP_ALGORITHM} algorithm...\")\n",
    "\n",
    "# Check if we have 3D data for gradient algorithm\n",
    "has_3d_data = SHAP_ALGORITHM == 'gradient' and 'X_3d' in locals() and 'shap_values_3d' in locals()\n",
    "\n",
    "# For kernel algorithm, we need to reshape the flattened values back to 3D\n",
    "if SHAP_ALGORITHM == 'kernel' and not has_3d_data:\n",
    "    if len(X_temporal_explain.shape) == 3 and len(shap_values.shape) == 2:\n",
    "        # Get original 3D dimensions\n",
    "        batch_size, seq_len, n_features = X_temporal_explain.shape\n",
    "\n",
    "        # Check if shap_values can be reshaped to match\n",
    "        if shap_values.shape[1] == seq_len * n_features:\n",
    "            print(f\"Reshaping kernel SHAP values from {shap_values.shape} back to 3D ({batch_size}, {seq_len}, {n_features})\")\n",
    "            try:\n",
    "                # Reshape flattened SHAP values back to 3D for temporal analysis\n",
    "                shap_values_3d = shap_values.reshape(batch_size, seq_len, n_features)\n",
    "                X_3d = X_temporal_explain\n",
    "                has_3d_data = True\n",
    "                print(\"Successfully reshaped kernel SHAP values for temporal analysis\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reshaping kernel SHAP values: {e}\")\n",
    "                has_3d_data = False\n",
    "        else:\n",
    "            print(f\"Cannot reshape kernel SHAP values: dimensions don't match. SHAP values shape: {shap_values.shape}, expected features: {seq_len * n_features}\")\n",
    "            has_3d_data = False\n",
    "    else:\n",
    "        print(f\"Cannot perform temporal analysis with kernel algorithm: input or SHAP values not in expected format\")\n",
    "        print(f\"X_temporal_explain shape: {X_temporal_explain.shape}, shap_values shape: {shap_values.shape}\")\n",
    "        has_3d_data = False\n",
    "\n",
    "# Generate temporal visualization if we have 3D data (either from gradient or reshaped kernel)\n",
    "if has_3d_data:\n",
    "    print(\"Generating temporal analysis plots...\")\n",
    "\n",
    "    # Calculate feature importance across time steps\n",
    "    batch_size, seq_len, n_features = shap_values_3d.shape\n",
    "    temporal_importance = np.abs(shap_values_3d).mean(axis=0)  # Shape: (seq_len, n_features)\n",
    "\n",
    "    # Create a plot showing feature importance across time steps\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Create a heatmap of temporal importance\n",
    "    plt.imshow(temporal_importance.T, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Mean |SHAP Value|')\n",
    "\n",
    "    # Set axis labels and ticks\n",
    "    plt.xlabel('Time Steps (t-n)')\n",
    "    plt.ylabel('Features')\n",
    "    # X-axis ticks are time steps from past to present\n",
    "    time_labels = [f't-{seq_len-1-i}' for i in range(seq_len)]\n",
    "    plt.xticks(range(seq_len), time_labels, rotation=45)\n",
    "    # Y-axis ticks are feature names\n",
    "    plt.yticks(range(n_features), temporal_features)\n",
    "\n",
    "    plt.title(f'{model_type.upper()} Temporal Feature Importance ({SHAP_ALGORITHM.capitalize()})')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    temporal_plot_path = output_dir / f\"{model_type}_{SHAP_ALGORITHM}_temporal_importance_{timestamp}.png\"\n",
    "    plt.savefig(temporal_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(f\"Temporal analysis plot saved to {temporal_plot_path}\")\n",
    "\n",
    "    # Create line plots for top features across time\n",
    "    # Identify top N features based on overall importance\n",
    "    top_n = 10\n",
    "    top_features_idx = np.argsort(np.mean(temporal_importance, axis=0))[-top_n:]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, feat_idx in enumerate(top_features_idx):\n",
    "        feat_name = temporal_features[feat_idx]\n",
    "        plt.plot(time_labels, temporal_importance[:, feat_idx],\n",
    "                marker='o', linewidth=2, label=feat_name)\n",
    "\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Feature Importance (Mean |SHAP Value|)')\n",
    "    plt.title(f'Top {top_n} Features Importance Across Time ({SHAP_ALGORITHM.capitalize()})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    top_features_path = output_dir / f\"{model_type}_{SHAP_ALGORITHM}_top_features_temporal_{timestamp}.png\"\n",
    "    plt.savefig(top_features_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(f\"Top features temporal analysis saved to {top_features_path}\")\n",
    "else:\n",
    "    print(\"Skipping temporal analysis (requires 3D data structures)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960eb4c4",
   "metadata": {},
   "source": [
    "### 7. Sensitivity Analysis (Alternative to SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06ade4d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"--- Running Sensitivity Analysis ---\")\n",
    "\n",
    "explainer = SensitivityAnalyzer(model, temporal_features, static_features)\n",
    "\n",
    "# Analyze feature sensitivity\n",
    "sensitivity_df = explainer.analyze_feature_sensitivity(\n",
    "    X_temporal_array,\n",
    "    X_static_array,\n",
    "    perturbation=0.1, # How much to perturb features\n",
    "    n_samples=min(10, X_temporal_array.shape[0]) # Number of samples to base analysis on\n",
    ")\n",
    "print(\"Sensitivity analysis complete.\")\n",
    "\n",
    "# Plot feature sensitivity\n",
    "print(\"Generating feature sensitivity plot...\")\n",
    "fig = explainer.plot_feature_sensitivity(\n",
    "    sensitivity_df,\n",
    "    max_display=50,\n",
    "    show=False,\n",
    "    title=f\"{model_type.upper()} Feature Sensitivity\"\n",
    ")\n",
    "sensitivity_plot_path = output_dir / f\"{model_type}_sensitivity.png\"\n",
    "fig.savefig(sensitivity_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "print(f\"Feature sensitivity plot saved to {sensitivity_plot_path}\")\n",
    "\n",
    "# Save sensitivity data\n",
    "sensitivity_csv_path = output_dir / f\"{model_type}_sensitivity.csv\"\n",
    "sensitivity_df.to_csv(sensitivity_csv_path, index=False)\n",
    "print(f\"Sensitivity data saved to {sensitivity_csv_path}\")\n",
    "print(\"Top 10 Features by Sensitivity:\")\n",
    "print(sensitivity_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
